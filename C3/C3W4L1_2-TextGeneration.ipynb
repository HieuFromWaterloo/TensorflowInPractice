{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"C3W4L1&2-TextGeneration.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOajLjOGVhahJoCv8JOQMs3"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"gbxTunhbLE9y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":377},"outputId":"72c95b59-a2a4-463d-a4e2-891d9917e1a7","executionInfo":{"status":"ok","timestamp":1579210537857,"user_tz":480,"elapsed":3703,"user":{"displayName":"Hieu Quoc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBXboZp2dMx_so4JiaOdf8YR1jpP73S07Pde39vvw=s64","userId":"07041430737003441740"}}},"source":["!pip install tensorflow==2.0.0-beta1"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow==2.0.0-beta1 in /usr/local/lib/python3.6/dist-packages (2.0.0b1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.15.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.12.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.9.0)\n","Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.14.0a20190603)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (3.10.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.11.2)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.33.6)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.1.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.1.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.0.8)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.17.5)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.8.1)\n","Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.14.0.dev2019060501)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.1.8)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.2.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (3.1.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (42.0.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (0.16.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta1) (2.8.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D1VsCmEuLR8d","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":445},"outputId":"280d09fc-72a3-40df-deae-7941cfd80f2b","executionInfo":{"status":"ok","timestamp":1579210539774,"user_tz":480,"elapsed":3445,"user":{"displayName":"Hieu Quoc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBXboZp2dMx_so4JiaOdf8YR1jpP73S07Pde39vvw=s64","userId":"07041430737003441740"}}},"source":["import tensorflow as tf\n","\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","import numpy as np"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"4_l4cR11Lf_0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"82aee31b-4a82-4880-a116-2cbe792ddcb7","executionInfo":{"status":"ok","timestamp":1579210539775,"user_tz":480,"elapsed":1137,"user":{"displayName":"Hieu Quoc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBXboZp2dMx_so4JiaOdf8YR1jpP73S07Pde39vvw=s64","userId":"07041430737003441740"}}},"source":["print(tf.__version__)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["2.0.0-beta1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Vtq0cSZwLjI0","colab_type":"code","colab":{}},"source":["# Define the data\n","data=\"In the town of Athy one Jeremy Lanigan \\n Battered away til he hadnt a pound. \\nHis father died and made him a man again \\n Left him a farm and ten acres of ground. \\nHe gave a grand party for friends and relations \\nWho didnt forget him when come to the wall, \\nAnd if youll but listen Ill make your eyes glisten \\nOf the rows and the ructions of Lanigans Ball. \\nMyself to be sure got free invitation, \\nFor all the nice girls and boys I might ask, \\nAnd just in a minute both friends and relations \\nWere dancing round merry as bees round a cask. \\nJudy ODaly, that nice little milliner, \\nShe tipped me a wink for to give her a call, \\nAnd I soon arrived with Peggy McGilligan \\nJust in time for Lanigans Ball. \\nThere were lashings of punch and wine for the ladies, \\nPotatoes and cakes; there was bacon and tea, \\nThere were the Nolans, Dolans, OGradys \\nCourting the girls and dancing away. \\nSongs they went round as plenty as water, \\nThe harp that once sounded in Taras old hall,\\nSweet Nelly Gray and The Rat Catchers Daughter,\\nAll singing together at Lanigans Ball. \\nThey were doing all kinds of nonsensical polkas \\nAll round the room in a whirligig. \\nJulia and I, we banished their nonsense \\nAnd tipped them the twist of a reel and a jig. \\nAch mavrone, how the girls got all mad at me \\nDanced til youd think the ceiling would fall. \\nFor I spent three weeks at Brooks Academy \\nLearning new steps for Lanigans Ball. \\nThree long weeks I spent up in Dublin, \\nThree long weeks to learn nothing at all,\\n Three long weeks I spent up in Dublin, \\nLearning new steps for Lanigans Ball. \\nShe stepped out and I stepped in again, \\nI stepped out and she stepped in again, \\nShe stepped out and I stepped in again, \\nLearning new steps for Lanigans Ball. \\nBoys were all merry and the girls they were hearty \\nAnd danced all around in couples and groups, \\nTil an accident happened, young Terrance McCarthy \\nPut his right leg through miss Finnertys hoops. \\nPoor creature fainted and cried Meelia murther, \\nCalled for her brothers and gathered them all. \\nCarmody swore that hed go no further \\nTil he had satisfaction at Lanigans Ball. \\nIn the midst of the row miss Kerrigan fainted, \\nHer cheeks at the same time as red as a rose. \\nSome of the lads declared she was painted, \\nShe took a small drop too much, I suppose. \\nHer sweetheart, Ned Morgan, so powerful and able, \\nWhen he saw his fair colleen stretched out by the wall, \\nTore the left leg from under the table \\nAnd smashed all the Chaneys at Lanigans Ball. \\nBoys, oh boys, twas then there were runctions. \\nMyself got a lick from big Phelim McHugh. \\nI soon replied to his introduction \\nAnd kicked up a terrible hullabaloo. \\nOld Casey, the piper, was near being strangled. \\nThey squeezed up his pipes, bellows, chanters and all. \\nThe girls, in their ribbons, they got all entangled \\nAnd that put an end to Lanigans Ball.\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FZF2dQ_tLnhc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"704c93d5-86a3-4f48-9b6e-fde1e5ba10f8","executionInfo":{"status":"ok","timestamp":1579208883310,"user_tz":480,"elapsed":892,"user":{"displayName":"Hieu Quoc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBXboZp2dMx_so4JiaOdf8YR1jpP73S07Pde39vvw=s64","userId":"07041430737003441740"}}},"source":["tokenizer = Tokenizer()\n","\n","corpus = data.lower().split(\"\\n\")\n","\n","# key value pairs: key = word, value = token\n","tokenizer.fit_on_texts(corpus)\n","# that that we + 1 to take into account OOV\n","total_words = len(tokenizer.word_index) + 1\n","\n","print(tokenizer.word_index)\n","print(total_words) # 263 TOTAL UNIQUE WORDS"],"execution_count":6,"outputs":[{"output_type":"stream","text":["{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n","263\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H8vUoe4sLzhz","colab_type":"code","colab":{}},"source":["# TRAINING BEGINS:\n","input_sequences = []\n","for line in corpus: # for each line in the corpus\n","  # we generate a list of tokens from each sentence in the corpus\n","  token_list = tokenizer.texts_to_sequences([line])[0]\n","  for i in range(1, len(token_list)):\n","    \"\"\"\n","    Then we'll iterate over this list of tokens and create a number of n-grams sequences, \n","    namely the first two words in the sentence are one sequence, then the first three are another sequence etc.\n","\n","    The same process will happen for each line, but as you can see, the input sequences \n","    are simply the sentences being broken down into phrases, the first two words, the first three words, etc. \n","    \"\"\"\n","    n_gram_sequence = token_list[:i+1]\n","    input_sequences.append(n_gram_sequence)\n","\n","# pad sequences:\n","## The longest length sentence in the corpus\n","max_sequence_len = max([len(x) for x in input_sequences])\n","## pre pad all sentences so that that have the same length then turns it into a np arrays for NN to process\n","## this makes it ezier to extract the labels later\n","input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n","\n","# create predictors and label\n","## Take every UP TO the 2nd LAST char as training, and out label will be the our pred target\n","xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n","## one hot encode labels\n","## NOTE: generating the next word in the seq is essentially a classification problem!\n","ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PFRNkQsfON3u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"f40a1f88-ceeb-452a-e358-bd1812b5bba5","executionInfo":{"status":"ok","timestamp":1579209576854,"user_tz":480,"elapsed":1055,"user":{"displayName":"Hieu Quoc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBXboZp2dMx_so4JiaOdf8YR1jpP73S07Pde39vvw=s64","userId":"07041430737003441740"}}},"source":["print(tokenizer.word_index['in'])\n","print(tokenizer.word_index['the'])\n","print(tokenizer.word_index['town'])\n","print(tokenizer.word_index['of'])\n","print(tokenizer.word_index['athy'])\n","print(tokenizer.word_index['one'])\n","print(tokenizer.word_index['jeremy'])\n","print(tokenizer.word_index['lanigan'])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["4\n","2\n","66\n","8\n","67\n","68\n","69\n","70\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7RMg_CyAOcz6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"outputId":"fd89f363-29d2-46de-8b2d-92ad72e3772f","executionInfo":{"status":"ok","timestamp":1579209602044,"user_tz":480,"elapsed":529,"user":{"displayName":"Hieu Quoc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBXboZp2dMx_so4JiaOdf8YR1jpP73S07Pde39vvw=s64","userId":"07041430737003441740"}}},"source":["print(xs[6])\n","print(ys[6])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[ 0  0  0  4  2 66  8 67 68 69]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_5EeLXB1OjFp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"outputId":"8255a855-ae8e-4bb1-84f7-1e9d1738338c","executionInfo":{"status":"ok","timestamp":1579209606367,"user_tz":480,"elapsed":600,"user":{"displayName":"Hieu Quoc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBXboZp2dMx_so4JiaOdf8YR1jpP73S07Pde39vvw=s64","userId":"07041430737003441740"}}},"source":["print(xs[5])\n","print(ys[5])"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[ 0  0  0  0  4  2 66  8 67 68]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pG2SDIajOkIo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"8d41ff36-7690-4810-b0d6-ceebb46bd3bf","executionInfo":{"status":"ok","timestamp":1579209616480,"user_tz":480,"elapsed":896,"user":{"displayName":"Hieu Quoc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBXboZp2dMx_so4JiaOdf8YR1jpP73S07Pde39vvw=s64","userId":"07041430737003441740"}}},"source":["print(tokenizer.word_index)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bHsQTTMTOmho","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"1516139f-556a-4de0-8ce4-5ad356dfe618","executionInfo":{"status":"ok","timestamp":1579209898048,"user_tz":480,"elapsed":106534,"user":{"displayName":"Hieu Quoc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBXboZp2dMx_so4JiaOdf8YR1jpP73S07Pde39vvw=s64","userId":"07041430737003441740"}}},"source":["# THE MODEL >>>>>>>>>>>>>>>>\n","# NOTE: we do not have a lot of data so thats why we train it on a lot more epochs\n","model = Sequential()\n","# Note that 64 is the embedded vector size\n","# max_sequence_len-1 because we crop off the last char as the label for each sequence\n","model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n","model.add(Bidirectional(LSTM(20)))\n","model.add(Dense(total_words, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","history = model.fit(xs, ys, epochs=500, verbose=1)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Train on 453 samples\n","Epoch 1/500\n","453/453 [==============================] - 2s 3ms/sample - loss: 5.5684 - accuracy: 0.0132\n","Epoch 2/500\n","453/453 [==============================] - 0s 526us/sample - loss: 5.5432 - accuracy: 0.0221\n","Epoch 3/500\n","453/453 [==============================] - 0s 453us/sample - loss: 5.4843 - accuracy: 0.0375\n","Epoch 4/500\n","453/453 [==============================] - 0s 434us/sample - loss: 5.3101 - accuracy: 0.0530\n","Epoch 5/500\n","453/453 [==============================] - 0s 443us/sample - loss: 5.1384 - accuracy: 0.0508\n","Epoch 6/500\n","453/453 [==============================] - 0s 462us/sample - loss: 5.0593 - accuracy: 0.0508\n","Epoch 7/500\n","453/453 [==============================] - 0s 458us/sample - loss: 5.0139 - accuracy: 0.0552\n","Epoch 8/500\n","453/453 [==============================] - 0s 444us/sample - loss: 4.9814 - accuracy: 0.0640\n","Epoch 9/500\n","453/453 [==============================] - 0s 420us/sample - loss: 4.9472 - accuracy: 0.0486\n","Epoch 10/500\n","453/453 [==============================] - 0s 424us/sample - loss: 4.9018 - accuracy: 0.0618\n","Epoch 11/500\n","453/453 [==============================] - 0s 432us/sample - loss: 4.8524 - accuracy: 0.0596\n","Epoch 12/500\n","453/453 [==============================] - 0s 469us/sample - loss: 4.8023 - accuracy: 0.0618\n","Epoch 13/500\n","453/453 [==============================] - 0s 440us/sample - loss: 4.7497 - accuracy: 0.0662\n","Epoch 14/500\n","453/453 [==============================] - 0s 442us/sample - loss: 4.6936 - accuracy: 0.0751\n","Epoch 15/500\n","453/453 [==============================] - 0s 443us/sample - loss: 4.6491 - accuracy: 0.0817\n","Epoch 16/500\n","453/453 [==============================] - 0s 427us/sample - loss: 4.5966 - accuracy: 0.0795\n","Epoch 17/500\n","453/453 [==============================] - 0s 440us/sample - loss: 4.5436 - accuracy: 0.0817\n","Epoch 18/500\n","453/453 [==============================] - 0s 444us/sample - loss: 4.4975 - accuracy: 0.0795\n","Epoch 19/500\n","453/453 [==============================] - 0s 449us/sample - loss: 4.4507 - accuracy: 0.0861\n","Epoch 20/500\n","453/453 [==============================] - 0s 430us/sample - loss: 4.4073 - accuracy: 0.0773\n","Epoch 21/500\n","453/453 [==============================] - 0s 455us/sample - loss: 4.3589 - accuracy: 0.0861\n","Epoch 22/500\n","453/453 [==============================] - 0s 441us/sample - loss: 4.3214 - accuracy: 0.0883\n","Epoch 23/500\n","453/453 [==============================] - 0s 421us/sample - loss: 4.2807 - accuracy: 0.1082\n","Epoch 24/500\n","453/453 [==============================] - 0s 428us/sample - loss: 4.2436 - accuracy: 0.1148\n","Epoch 25/500\n","453/453 [==============================] - 0s 440us/sample - loss: 4.2209 - accuracy: 0.1280\n","Epoch 26/500\n","453/453 [==============================] - 0s 440us/sample - loss: 4.1705 - accuracy: 0.1302\n","Epoch 27/500\n","453/453 [==============================] - 0s 442us/sample - loss: 4.1306 - accuracy: 0.1280\n","Epoch 28/500\n","453/453 [==============================] - 0s 439us/sample - loss: 4.0845 - accuracy: 0.1170\n","Epoch 29/500\n","453/453 [==============================] - 0s 437us/sample - loss: 4.0454 - accuracy: 0.1325\n","Epoch 30/500\n","453/453 [==============================] - 0s 432us/sample - loss: 3.9976 - accuracy: 0.1435\n","Epoch 31/500\n","453/453 [==============================] - 0s 443us/sample - loss: 3.9615 - accuracy: 0.1501\n","Epoch 32/500\n","453/453 [==============================] - 0s 440us/sample - loss: 3.9262 - accuracy: 0.1567\n","Epoch 33/500\n","453/453 [==============================] - 0s 443us/sample - loss: 3.8882 - accuracy: 0.1523\n","Epoch 34/500\n","453/453 [==============================] - 0s 432us/sample - loss: 3.8516 - accuracy: 0.1700\n","Epoch 35/500\n","453/453 [==============================] - 0s 445us/sample - loss: 3.8115 - accuracy: 0.1854\n","Epoch 36/500\n","453/453 [==============================] - 0s 451us/sample - loss: 3.7800 - accuracy: 0.1810\n","Epoch 37/500\n","453/453 [==============================] - 0s 450us/sample - loss: 3.7405 - accuracy: 0.1965\n","Epoch 38/500\n","453/453 [==============================] - 0s 431us/sample - loss: 3.7228 - accuracy: 0.2031\n","Epoch 39/500\n","453/453 [==============================] - 0s 448us/sample - loss: 3.6710 - accuracy: 0.2208\n","Epoch 40/500\n","453/453 [==============================] - 0s 436us/sample - loss: 3.6382 - accuracy: 0.2208\n","Epoch 41/500\n","453/453 [==============================] - 0s 444us/sample - loss: 3.5974 - accuracy: 0.2340\n","Epoch 42/500\n","453/453 [==============================] - 0s 438us/sample - loss: 3.5740 - accuracy: 0.2494\n","Epoch 43/500\n","453/453 [==============================] - 0s 433us/sample - loss: 3.5632 - accuracy: 0.2583\n","Epoch 44/500\n","453/453 [==============================] - 0s 442us/sample - loss: 3.5029 - accuracy: 0.2737\n","Epoch 45/500\n","453/453 [==============================] - 0s 433us/sample - loss: 3.4625 - accuracy: 0.2583\n","Epoch 46/500\n","453/453 [==============================] - 0s 461us/sample - loss: 3.4191 - accuracy: 0.2781\n","Epoch 47/500\n","453/453 [==============================] - 0s 424us/sample - loss: 3.3795 - accuracy: 0.2826\n","Epoch 48/500\n","453/453 [==============================] - 0s 445us/sample - loss: 3.3400 - accuracy: 0.2848\n","Epoch 49/500\n","453/453 [==============================] - 0s 433us/sample - loss: 3.3031 - accuracy: 0.3157\n","Epoch 50/500\n","453/453 [==============================] - 0s 480us/sample - loss: 3.2730 - accuracy: 0.3245\n","Epoch 51/500\n","453/453 [==============================] - 0s 445us/sample - loss: 3.2329 - accuracy: 0.3333\n","Epoch 52/500\n","453/453 [==============================] - 0s 430us/sample - loss: 3.1969 - accuracy: 0.3422\n","Epoch 53/500\n","453/453 [==============================] - 0s 441us/sample - loss: 3.1679 - accuracy: 0.3444\n","Epoch 54/500\n","453/453 [==============================] - 0s 445us/sample - loss: 3.1289 - accuracy: 0.3687\n","Epoch 55/500\n","453/453 [==============================] - 0s 449us/sample - loss: 3.1112 - accuracy: 0.3598\n","Epoch 56/500\n","453/453 [==============================] - 0s 445us/sample - loss: 3.0623 - accuracy: 0.3775\n","Epoch 57/500\n","453/453 [==============================] - 0s 446us/sample - loss: 3.0243 - accuracy: 0.3819\n","Epoch 58/500\n","453/453 [==============================] - 0s 434us/sample - loss: 2.9932 - accuracy: 0.4040\n","Epoch 59/500\n","453/453 [==============================] - 0s 438us/sample - loss: 2.9598 - accuracy: 0.4106\n","Epoch 60/500\n","453/453 [==============================] - 0s 450us/sample - loss: 2.9292 - accuracy: 0.4084\n","Epoch 61/500\n","453/453 [==============================] - 0s 451us/sample - loss: 2.8967 - accuracy: 0.4260\n","Epoch 62/500\n","453/453 [==============================] - 0s 428us/sample - loss: 2.8642 - accuracy: 0.4305\n","Epoch 63/500\n","453/453 [==============================] - 0s 470us/sample - loss: 2.8260 - accuracy: 0.4216\n","Epoch 64/500\n","453/453 [==============================] - 0s 444us/sample - loss: 2.7955 - accuracy: 0.4393\n","Epoch 65/500\n","453/453 [==============================] - 0s 459us/sample - loss: 2.7775 - accuracy: 0.4327\n","Epoch 66/500\n","453/453 [==============================] - 0s 435us/sample - loss: 2.7410 - accuracy: 0.4481\n","Epoch 67/500\n","453/453 [==============================] - 0s 432us/sample - loss: 2.7151 - accuracy: 0.4592\n","Epoch 68/500\n","453/453 [==============================] - 0s 436us/sample - loss: 2.6892 - accuracy: 0.4636\n","Epoch 69/500\n","453/453 [==============================] - 0s 443us/sample - loss: 2.6589 - accuracy: 0.4790\n","Epoch 70/500\n","453/453 [==============================] - 0s 453us/sample - loss: 2.6282 - accuracy: 0.4834\n","Epoch 71/500\n","453/453 [==============================] - 0s 439us/sample - loss: 2.6244 - accuracy: 0.4923\n","Epoch 72/500\n","453/453 [==============================] - 0s 445us/sample - loss: 2.6153 - accuracy: 0.4724\n","Epoch 73/500\n","453/453 [==============================] - 0s 445us/sample - loss: 2.5825 - accuracy: 0.4967\n","Epoch 74/500\n","453/453 [==============================] - 0s 446us/sample - loss: 2.5498 - accuracy: 0.5077\n","Epoch 75/500\n","453/453 [==============================] - 0s 435us/sample - loss: 2.5046 - accuracy: 0.5276\n","Epoch 76/500\n","453/453 [==============================] - 0s 460us/sample - loss: 2.4796 - accuracy: 0.5210\n","Epoch 77/500\n","453/453 [==============================] - 0s 445us/sample - loss: 2.4504 - accuracy: 0.5430\n","Epoch 78/500\n","453/453 [==============================] - 0s 450us/sample - loss: 2.4221 - accuracy: 0.5408\n","Epoch 79/500\n","453/453 [==============================] - 0s 437us/sample - loss: 2.3948 - accuracy: 0.5386\n","Epoch 80/500\n","453/453 [==============================] - 0s 442us/sample - loss: 2.3710 - accuracy: 0.5386\n","Epoch 81/500\n","453/453 [==============================] - 0s 436us/sample - loss: 2.3416 - accuracy: 0.5386\n","Epoch 82/500\n","453/453 [==============================] - 0s 438us/sample - loss: 2.3228 - accuracy: 0.5629\n","Epoch 83/500\n","453/453 [==============================] - 0s 442us/sample - loss: 2.2986 - accuracy: 0.5762\n","Epoch 84/500\n","453/453 [==============================] - 0s 439us/sample - loss: 2.2744 - accuracy: 0.5585\n","Epoch 85/500\n","453/453 [==============================] - 0s 444us/sample - loss: 2.2503 - accuracy: 0.5740\n","Epoch 86/500\n","453/453 [==============================] - 0s 473us/sample - loss: 2.2272 - accuracy: 0.5938\n","Epoch 87/500\n","453/453 [==============================] - 0s 437us/sample - loss: 2.2009 - accuracy: 0.5894\n","Epoch 88/500\n","453/453 [==============================] - 0s 450us/sample - loss: 2.1861 - accuracy: 0.5894\n","Epoch 89/500\n","453/453 [==============================] - 0s 433us/sample - loss: 2.1744 - accuracy: 0.5850\n","Epoch 90/500\n","453/453 [==============================] - 0s 445us/sample - loss: 2.1368 - accuracy: 0.6026\n","Epoch 91/500\n","453/453 [==============================] - 0s 432us/sample - loss: 2.1247 - accuracy: 0.6203\n","Epoch 92/500\n","453/453 [==============================] - 0s 433us/sample - loss: 2.1027 - accuracy: 0.6247\n","Epoch 93/500\n","453/453 [==============================] - 0s 440us/sample - loss: 2.0800 - accuracy: 0.6225\n","Epoch 94/500\n","453/453 [==============================] - 0s 452us/sample - loss: 2.0510 - accuracy: 0.6424\n","Epoch 95/500\n","453/453 [==============================] - 0s 444us/sample - loss: 2.0318 - accuracy: 0.6468\n","Epoch 96/500\n","453/453 [==============================] - 0s 429us/sample - loss: 2.0079 - accuracy: 0.6490\n","Epoch 97/500\n","453/453 [==============================] - 0s 435us/sample - loss: 1.9878 - accuracy: 0.6556\n","Epoch 98/500\n","453/453 [==============================] - 0s 448us/sample - loss: 1.9696 - accuracy: 0.6578\n","Epoch 99/500\n","453/453 [==============================] - 0s 435us/sample - loss: 1.9556 - accuracy: 0.6534\n","Epoch 100/500\n","453/453 [==============================] - 0s 436us/sample - loss: 1.9349 - accuracy: 0.6667\n","Epoch 101/500\n","453/453 [==============================] - 0s 454us/sample - loss: 1.9116 - accuracy: 0.6667\n","Epoch 102/500\n","453/453 [==============================] - 0s 422us/sample - loss: 1.8953 - accuracy: 0.6777\n","Epoch 103/500\n","453/453 [==============================] - 0s 429us/sample - loss: 1.8893 - accuracy: 0.6777\n","Epoch 104/500\n","453/453 [==============================] - 0s 432us/sample - loss: 1.8657 - accuracy: 0.6843\n","Epoch 105/500\n","453/453 [==============================] - 0s 442us/sample - loss: 1.8539 - accuracy: 0.6821\n","Epoch 106/500\n","453/453 [==============================] - 0s 427us/sample - loss: 1.8454 - accuracy: 0.6821\n","Epoch 107/500\n","453/453 [==============================] - 0s 439us/sample - loss: 1.8151 - accuracy: 0.6932\n","Epoch 108/500\n","453/453 [==============================] - 0s 451us/sample - loss: 1.7924 - accuracy: 0.6887\n","Epoch 109/500\n","453/453 [==============================] - 0s 439us/sample - loss: 1.7671 - accuracy: 0.6998\n","Epoch 110/500\n","453/453 [==============================] - 0s 443us/sample - loss: 1.7381 - accuracy: 0.7108\n","Epoch 111/500\n","453/453 [==============================] - 0s 435us/sample - loss: 1.7255 - accuracy: 0.7196\n","Epoch 112/500\n","453/453 [==============================] - 0s 445us/sample - loss: 1.7076 - accuracy: 0.7130\n","Epoch 113/500\n","453/453 [==============================] - 0s 445us/sample - loss: 1.6917 - accuracy: 0.7196\n","Epoch 114/500\n","453/453 [==============================] - 0s 440us/sample - loss: 1.6719 - accuracy: 0.7219\n","Epoch 115/500\n","453/453 [==============================] - 0s 435us/sample - loss: 1.6547 - accuracy: 0.7285\n","Epoch 116/500\n","453/453 [==============================] - 0s 429us/sample - loss: 1.6365 - accuracy: 0.7307\n","Epoch 117/500\n","453/453 [==============================] - 0s 445us/sample - loss: 1.6226 - accuracy: 0.7351\n","Epoch 118/500\n","453/453 [==============================] - 0s 455us/sample - loss: 1.6075 - accuracy: 0.7351\n","Epoch 119/500\n","453/453 [==============================] - 0s 461us/sample - loss: 1.6034 - accuracy: 0.7373\n","Epoch 120/500\n","453/453 [==============================] - 0s 439us/sample - loss: 1.5889 - accuracy: 0.7373\n","Epoch 121/500\n","453/453 [==============================] - 0s 430us/sample - loss: 1.5688 - accuracy: 0.7439\n","Epoch 122/500\n","453/453 [==============================] - 0s 447us/sample - loss: 1.5478 - accuracy: 0.7594\n","Epoch 123/500\n","453/453 [==============================] - 0s 419us/sample - loss: 1.5339 - accuracy: 0.7528\n","Epoch 124/500\n","453/453 [==============================] - 0s 426us/sample - loss: 1.5205 - accuracy: 0.7616\n","Epoch 125/500\n","453/453 [==============================] - 0s 446us/sample - loss: 1.5123 - accuracy: 0.7550\n","Epoch 126/500\n","453/453 [==============================] - 0s 446us/sample - loss: 1.5072 - accuracy: 0.7483\n","Epoch 127/500\n","453/453 [==============================] - 0s 431us/sample - loss: 1.5020 - accuracy: 0.7572\n","Epoch 128/500\n","453/453 [==============================] - 0s 438us/sample - loss: 1.4796 - accuracy: 0.7616\n","Epoch 129/500\n","453/453 [==============================] - 0s 476us/sample - loss: 1.4645 - accuracy: 0.7483\n","Epoch 130/500\n","453/453 [==============================] - 0s 438us/sample - loss: 1.4399 - accuracy: 0.7638\n","Epoch 131/500\n","453/453 [==============================] - 0s 454us/sample - loss: 1.4246 - accuracy: 0.7682\n","Epoch 132/500\n","453/453 [==============================] - 0s 449us/sample - loss: 1.4405 - accuracy: 0.7483\n","Epoch 133/500\n","453/453 [==============================] - 0s 447us/sample - loss: 1.4363 - accuracy: 0.7660\n","Epoch 134/500\n","453/453 [==============================] - 0s 455us/sample - loss: 1.4353 - accuracy: 0.7417\n","Epoch 135/500\n","453/453 [==============================] - 0s 451us/sample - loss: 1.4102 - accuracy: 0.7682\n","Epoch 136/500\n","453/453 [==============================] - 0s 459us/sample - loss: 1.3815 - accuracy: 0.7704\n","Epoch 137/500\n","453/453 [==============================] - 0s 440us/sample - loss: 1.3765 - accuracy: 0.7748\n","Epoch 138/500\n","453/453 [==============================] - 0s 466us/sample - loss: 1.3519 - accuracy: 0.7881\n","Epoch 139/500\n","453/453 [==============================] - 0s 448us/sample - loss: 1.3326 - accuracy: 0.7881\n","Epoch 140/500\n","453/453 [==============================] - 0s 438us/sample - loss: 1.3169 - accuracy: 0.7925\n","Epoch 141/500\n","453/453 [==============================] - 0s 441us/sample - loss: 1.3028 - accuracy: 0.7947\n","Epoch 142/500\n","453/453 [==============================] - 0s 444us/sample - loss: 1.2877 - accuracy: 0.7947\n","Epoch 143/500\n","453/453 [==============================] - 0s 469us/sample - loss: 1.2751 - accuracy: 0.7903\n","Epoch 144/500\n","453/453 [==============================] - 0s 442us/sample - loss: 1.2630 - accuracy: 0.8013\n","Epoch 145/500\n","453/453 [==============================] - 0s 438us/sample - loss: 1.2476 - accuracy: 0.8057\n","Epoch 146/500\n","453/453 [==============================] - 0s 447us/sample - loss: 1.2348 - accuracy: 0.8102\n","Epoch 147/500\n","453/453 [==============================] - 0s 454us/sample - loss: 1.2181 - accuracy: 0.8190\n","Epoch 148/500\n","453/453 [==============================] - 0s 453us/sample - loss: 1.2015 - accuracy: 0.8146\n","Epoch 149/500\n","453/453 [==============================] - 0s 447us/sample - loss: 1.1888 - accuracy: 0.8212\n","Epoch 150/500\n","453/453 [==============================] - 0s 445us/sample - loss: 1.1776 - accuracy: 0.8212\n","Epoch 151/500\n","453/453 [==============================] - 0s 453us/sample - loss: 1.1658 - accuracy: 0.8212\n","Epoch 152/500\n","453/453 [==============================] - 0s 438us/sample - loss: 1.1532 - accuracy: 0.8212\n","Epoch 153/500\n","453/453 [==============================] - 0s 439us/sample - loss: 1.1420 - accuracy: 0.8212\n","Epoch 154/500\n","453/453 [==============================] - 0s 415us/sample - loss: 1.1326 - accuracy: 0.8300\n","Epoch 155/500\n","453/453 [==============================] - 0s 438us/sample - loss: 1.1202 - accuracy: 0.8433\n","Epoch 156/500\n","453/453 [==============================] - 0s 443us/sample - loss: 1.1119 - accuracy: 0.8433\n","Epoch 157/500\n","453/453 [==============================] - 0s 429us/sample - loss: 1.1020 - accuracy: 0.8322\n","Epoch 158/500\n","453/453 [==============================] - 0s 437us/sample - loss: 1.0891 - accuracy: 0.8366\n","Epoch 159/500\n","453/453 [==============================] - 0s 446us/sample - loss: 1.0802 - accuracy: 0.8433\n","Epoch 160/500\n","453/453 [==============================] - 0s 451us/sample - loss: 1.0746 - accuracy: 0.8433\n","Epoch 161/500\n","453/453 [==============================] - 0s 441us/sample - loss: 1.0821 - accuracy: 0.8389\n","Epoch 162/500\n","453/453 [==============================] - 0s 443us/sample - loss: 1.0618 - accuracy: 0.8411\n","Epoch 163/500\n","453/453 [==============================] - 0s 432us/sample - loss: 1.0495 - accuracy: 0.8521\n","Epoch 164/500\n","453/453 [==============================] - 0s 429us/sample - loss: 1.0382 - accuracy: 0.8587\n","Epoch 165/500\n","453/453 [==============================] - 0s 450us/sample - loss: 1.0296 - accuracy: 0.8609\n","Epoch 166/500\n","453/453 [==============================] - 0s 441us/sample - loss: 1.0440 - accuracy: 0.8521\n","Epoch 167/500\n","453/453 [==============================] - 0s 442us/sample - loss: 1.0358 - accuracy: 0.8411\n","Epoch 168/500\n","453/453 [==============================] - 0s 434us/sample - loss: 1.0311 - accuracy: 0.8521\n","Epoch 169/500\n","453/453 [==============================] - 0s 426us/sample - loss: 1.0223 - accuracy: 0.8477\n","Epoch 170/500\n","453/453 [==============================] - 0s 447us/sample - loss: 0.9957 - accuracy: 0.8521\n","Epoch 171/500\n","453/453 [==============================] - 0s 428us/sample - loss: 0.9803 - accuracy: 0.8631\n","Epoch 172/500\n","453/453 [==============================] - 0s 445us/sample - loss: 0.9638 - accuracy: 0.8587\n","Epoch 173/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.9669 - accuracy: 0.8587\n","Epoch 174/500\n","453/453 [==============================] - 0s 465us/sample - loss: 0.9526 - accuracy: 0.8653\n","Epoch 175/500\n","453/453 [==============================] - 0s 450us/sample - loss: 0.9346 - accuracy: 0.8720\n","Epoch 176/500\n","453/453 [==============================] - 0s 438us/sample - loss: 0.9347 - accuracy: 0.8675\n","Epoch 177/500\n","453/453 [==============================] - 0s 438us/sample - loss: 0.9212 - accuracy: 0.8720\n","Epoch 178/500\n","453/453 [==============================] - 0s 433us/sample - loss: 0.9499 - accuracy: 0.8565\n","Epoch 179/500\n","453/453 [==============================] - 0s 433us/sample - loss: 1.1286 - accuracy: 0.7881\n","Epoch 180/500\n","453/453 [==============================] - 0s 434us/sample - loss: 1.0917 - accuracy: 0.8124\n","Epoch 181/500\n","453/453 [==============================] - 0s 445us/sample - loss: 1.0507 - accuracy: 0.8300\n","Epoch 182/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.9932 - accuracy: 0.8477\n","Epoch 183/500\n","453/453 [==============================] - 0s 444us/sample - loss: 0.9210 - accuracy: 0.8631\n","Epoch 184/500\n","453/453 [==============================] - 0s 453us/sample - loss: 0.8994 - accuracy: 0.8698\n","Epoch 185/500\n","453/453 [==============================] - 0s 436us/sample - loss: 0.8743 - accuracy: 0.8808\n","Epoch 186/500\n","453/453 [==============================] - 0s 456us/sample - loss: 0.8588 - accuracy: 0.8808\n","Epoch 187/500\n","453/453 [==============================] - 0s 439us/sample - loss: 0.8464 - accuracy: 0.8808\n","Epoch 188/500\n","453/453 [==============================] - 0s 444us/sample - loss: 0.8511 - accuracy: 0.8786\n","Epoch 189/500\n","453/453 [==============================] - 0s 420us/sample - loss: 0.8354 - accuracy: 0.8830\n","Epoch 190/500\n","453/453 [==============================] - 0s 439us/sample - loss: 0.8224 - accuracy: 0.8896\n","Epoch 191/500\n","453/453 [==============================] - 0s 446us/sample - loss: 0.8116 - accuracy: 0.8896\n","Epoch 192/500\n","453/453 [==============================] - 0s 449us/sample - loss: 0.8017 - accuracy: 0.8918\n","Epoch 193/500\n","453/453 [==============================] - 0s 502us/sample - loss: 0.7974 - accuracy: 0.8852\n","Epoch 194/500\n","453/453 [==============================] - 0s 429us/sample - loss: 0.7851 - accuracy: 0.8874\n","Epoch 195/500\n","453/453 [==============================] - 0s 435us/sample - loss: 0.7782 - accuracy: 0.8918\n","Epoch 196/500\n","453/453 [==============================] - 0s 444us/sample - loss: 0.7668 - accuracy: 0.8874\n","Epoch 197/500\n","453/453 [==============================] - 0s 439us/sample - loss: 0.7581 - accuracy: 0.8874\n","Epoch 198/500\n","453/453 [==============================] - 0s 464us/sample - loss: 0.7518 - accuracy: 0.8962\n","Epoch 199/500\n","453/453 [==============================] - 0s 448us/sample - loss: 0.7434 - accuracy: 0.9029\n","Epoch 200/500\n","453/453 [==============================] - 0s 426us/sample - loss: 0.7374 - accuracy: 0.8962\n","Epoch 201/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.7311 - accuracy: 0.9029\n","Epoch 202/500\n","453/453 [==============================] - 0s 419us/sample - loss: 0.7269 - accuracy: 0.8940\n","Epoch 203/500\n","453/453 [==============================] - 0s 443us/sample - loss: 0.7193 - accuracy: 0.8985\n","Epoch 204/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.7107 - accuracy: 0.8985\n","Epoch 205/500\n","453/453 [==============================] - 0s 430us/sample - loss: 0.7036 - accuracy: 0.9007\n","Epoch 206/500\n","453/453 [==============================] - 0s 425us/sample - loss: 0.6991 - accuracy: 0.9051\n","Epoch 207/500\n","453/453 [==============================] - 0s 456us/sample - loss: 0.6920 - accuracy: 0.9073\n","Epoch 208/500\n","453/453 [==============================] - 0s 446us/sample - loss: 0.6849 - accuracy: 0.9051\n","Epoch 209/500\n","453/453 [==============================] - 0s 426us/sample - loss: 0.6787 - accuracy: 0.9073\n","Epoch 210/500\n","453/453 [==============================] - 0s 457us/sample - loss: 0.6742 - accuracy: 0.9095\n","Epoch 211/500\n","453/453 [==============================] - 0s 440us/sample - loss: 0.6683 - accuracy: 0.9073\n","Epoch 212/500\n","453/453 [==============================] - 0s 430us/sample - loss: 0.6666 - accuracy: 0.9051\n","Epoch 213/500\n","453/453 [==============================] - 0s 436us/sample - loss: 0.6623 - accuracy: 0.9161\n","Epoch 214/500\n","453/453 [==============================] - 0s 474us/sample - loss: 0.6561 - accuracy: 0.9139\n","Epoch 215/500\n","453/453 [==============================] - 0s 455us/sample - loss: 0.6505 - accuracy: 0.9051\n","Epoch 216/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.6401 - accuracy: 0.9161\n","Epoch 217/500\n","453/453 [==============================] - 0s 442us/sample - loss: 0.6346 - accuracy: 0.9117\n","Epoch 218/500\n","453/453 [==============================] - 0s 437us/sample - loss: 0.6258 - accuracy: 0.9095\n","Epoch 219/500\n","453/453 [==============================] - 0s 446us/sample - loss: 0.6196 - accuracy: 0.9073\n","Epoch 220/500\n","453/453 [==============================] - 0s 446us/sample - loss: 0.6133 - accuracy: 0.9139\n","Epoch 221/500\n","453/453 [==============================] - 0s 443us/sample - loss: 0.6086 - accuracy: 0.9183\n","Epoch 222/500\n","453/453 [==============================] - 0s 431us/sample - loss: 0.6030 - accuracy: 0.9117\n","Epoch 223/500\n","453/453 [==============================] - 0s 459us/sample - loss: 0.5972 - accuracy: 0.9161\n","Epoch 224/500\n","453/453 [==============================] - 0s 437us/sample - loss: 0.5917 - accuracy: 0.9205\n","Epoch 225/500\n","453/453 [==============================] - 0s 447us/sample - loss: 0.5862 - accuracy: 0.9227\n","Epoch 226/500\n","453/453 [==============================] - 0s 443us/sample - loss: 0.5812 - accuracy: 0.9249\n","Epoch 227/500\n","453/453 [==============================] - 0s 443us/sample - loss: 0.5764 - accuracy: 0.9183\n","Epoch 228/500\n","453/453 [==============================] - 0s 451us/sample - loss: 0.5708 - accuracy: 0.9227\n","Epoch 229/500\n","453/453 [==============================] - 0s 429us/sample - loss: 0.5652 - accuracy: 0.9249\n","Epoch 230/500\n","453/453 [==============================] - 0s 483us/sample - loss: 0.5614 - accuracy: 0.9272\n","Epoch 231/500\n","453/453 [==============================] - 0s 457us/sample - loss: 0.5544 - accuracy: 0.9272\n","Epoch 232/500\n","453/453 [==============================] - 0s 444us/sample - loss: 0.5498 - accuracy: 0.9272\n","Epoch 233/500\n","453/453 [==============================] - 0s 446us/sample - loss: 0.5458 - accuracy: 0.9249\n","Epoch 234/500\n","453/453 [==============================] - 0s 445us/sample - loss: 0.5416 - accuracy: 0.9249\n","Epoch 235/500\n","453/453 [==============================] - 0s 446us/sample - loss: 0.5375 - accuracy: 0.9272\n","Epoch 236/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.5371 - accuracy: 0.9249\n","Epoch 237/500\n","453/453 [==============================] - 0s 450us/sample - loss: 0.5300 - accuracy: 0.9249\n","Epoch 238/500\n","453/453 [==============================] - 0s 457us/sample - loss: 0.5265 - accuracy: 0.9272\n","Epoch 239/500\n","453/453 [==============================] - 0s 443us/sample - loss: 0.5234 - accuracy: 0.9249\n","Epoch 240/500\n","453/453 [==============================] - 0s 447us/sample - loss: 0.5157 - accuracy: 0.9294\n","Epoch 241/500\n","453/453 [==============================] - 0s 450us/sample - loss: 0.5109 - accuracy: 0.9316\n","Epoch 242/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.5058 - accuracy: 0.9272\n","Epoch 243/500\n","453/453 [==============================] - 0s 439us/sample - loss: 0.5015 - accuracy: 0.9294\n","Epoch 244/500\n","453/453 [==============================] - 0s 452us/sample - loss: 0.4968 - accuracy: 0.9360\n","Epoch 245/500\n","453/453 [==============================] - 0s 450us/sample - loss: 0.4919 - accuracy: 0.9316\n","Epoch 246/500\n","453/453 [==============================] - 0s 445us/sample - loss: 0.4887 - accuracy: 0.9338\n","Epoch 247/500\n","453/453 [==============================] - 0s 444us/sample - loss: 0.4890 - accuracy: 0.9272\n","Epoch 248/500\n","453/453 [==============================] - 0s 456us/sample - loss: 0.4830 - accuracy: 0.9316\n","Epoch 249/500\n","453/453 [==============================] - 0s 425us/sample - loss: 0.4792 - accuracy: 0.9338\n","Epoch 250/500\n","453/453 [==============================] - 0s 416us/sample - loss: 0.4805 - accuracy: 0.9227\n","Epoch 251/500\n","453/453 [==============================] - 0s 442us/sample - loss: 0.4799 - accuracy: 0.9227\n","Epoch 252/500\n","453/453 [==============================] - 0s 421us/sample - loss: 0.4745 - accuracy: 0.9249\n","Epoch 253/500\n","453/453 [==============================] - 0s 457us/sample - loss: 0.4655 - accuracy: 0.9338\n","Epoch 254/500\n","453/453 [==============================] - 0s 432us/sample - loss: 0.4613 - accuracy: 0.9294\n","Epoch 255/500\n","453/453 [==============================] - 0s 440us/sample - loss: 0.4590 - accuracy: 0.9294\n","Epoch 256/500\n","453/453 [==============================] - 0s 445us/sample - loss: 0.4518 - accuracy: 0.9338\n","Epoch 257/500\n","453/453 [==============================] - 0s 445us/sample - loss: 0.4486 - accuracy: 0.9249\n","Epoch 258/500\n","453/453 [==============================] - 0s 430us/sample - loss: 0.4435 - accuracy: 0.9316\n","Epoch 259/500\n","453/453 [==============================] - 0s 450us/sample - loss: 0.4395 - accuracy: 0.9294\n","Epoch 260/500\n","453/453 [==============================] - 0s 433us/sample - loss: 0.4356 - accuracy: 0.9294\n","Epoch 261/500\n","453/453 [==============================] - 0s 450us/sample - loss: 0.4317 - accuracy: 0.9338\n","Epoch 262/500\n","453/453 [==============================] - 0s 405us/sample - loss: 0.4283 - accuracy: 0.9338\n","Epoch 263/500\n","453/453 [==============================] - 0s 438us/sample - loss: 0.4248 - accuracy: 0.9338\n","Epoch 264/500\n","453/453 [==============================] - 0s 442us/sample - loss: 0.4212 - accuracy: 0.9316\n","Epoch 265/500\n","453/453 [==============================] - 0s 446us/sample - loss: 0.4184 - accuracy: 0.9316\n","Epoch 266/500\n","453/453 [==============================] - 0s 444us/sample - loss: 0.4149 - accuracy: 0.9360\n","Epoch 267/500\n","453/453 [==============================] - 0s 444us/sample - loss: 0.4126 - accuracy: 0.9294\n","Epoch 268/500\n","453/453 [==============================] - 0s 432us/sample - loss: 0.4077 - accuracy: 0.9316\n","Epoch 269/500\n","453/453 [==============================] - 0s 439us/sample - loss: 0.4038 - accuracy: 0.9360\n","Epoch 270/500\n","453/453 [==============================] - 0s 453us/sample - loss: 0.4013 - accuracy: 0.9360\n","Epoch 271/500\n","453/453 [==============================] - 0s 436us/sample - loss: 0.3982 - accuracy: 0.9360\n","Epoch 272/500\n","453/453 [==============================] - 0s 447us/sample - loss: 0.3959 - accuracy: 0.9382\n","Epoch 273/500\n","453/453 [==============================] - 0s 447us/sample - loss: 0.3924 - accuracy: 0.9404\n","Epoch 274/500\n","453/453 [==============================] - 0s 446us/sample - loss: 0.3891 - accuracy: 0.9404\n","Epoch 275/500\n","453/453 [==============================] - 0s 437us/sample - loss: 0.3866 - accuracy: 0.9426\n","Epoch 276/500\n","453/453 [==============================] - 0s 437us/sample - loss: 0.3846 - accuracy: 0.9382\n","Epoch 277/500\n","453/453 [==============================] - 0s 450us/sample - loss: 0.3811 - accuracy: 0.9360\n","Epoch 278/500\n","453/453 [==============================] - 0s 438us/sample - loss: 0.3791 - accuracy: 0.9382\n","Epoch 279/500\n","453/453 [==============================] - 0s 449us/sample - loss: 0.3759 - accuracy: 0.9382\n","Epoch 280/500\n","453/453 [==============================] - 0s 448us/sample - loss: 0.3726 - accuracy: 0.9404\n","Epoch 281/500\n","453/453 [==============================] - 0s 447us/sample - loss: 0.3694 - accuracy: 0.9404\n","Epoch 282/500\n","453/453 [==============================] - 0s 436us/sample - loss: 0.3666 - accuracy: 0.9382\n","Epoch 283/500\n","453/453 [==============================] - 0s 434us/sample - loss: 0.3637 - accuracy: 0.9382\n","Epoch 284/500\n","453/453 [==============================] - 0s 448us/sample - loss: 0.3602 - accuracy: 0.9404\n","Epoch 285/500\n","453/453 [==============================] - 0s 442us/sample - loss: 0.3577 - accuracy: 0.9404\n","Epoch 286/500\n","453/453 [==============================] - 0s 439us/sample - loss: 0.3552 - accuracy: 0.9382\n","Epoch 287/500\n","453/453 [==============================] - 0s 443us/sample - loss: 0.3529 - accuracy: 0.9382\n","Epoch 288/500\n","453/453 [==============================] - 0s 460us/sample - loss: 0.3500 - accuracy: 0.9404\n","Epoch 289/500\n","453/453 [==============================] - 0s 432us/sample - loss: 0.3475 - accuracy: 0.9382\n","Epoch 290/500\n","453/453 [==============================] - 0s 432us/sample - loss: 0.3457 - accuracy: 0.9426\n","Epoch 291/500\n","453/453 [==============================] - 0s 446us/sample - loss: 0.3426 - accuracy: 0.9426\n","Epoch 292/500\n","453/453 [==============================] - 0s 447us/sample - loss: 0.3407 - accuracy: 0.9426\n","Epoch 293/500\n","453/453 [==============================] - 0s 431us/sample - loss: 0.3372 - accuracy: 0.9404\n","Epoch 294/500\n","453/453 [==============================] - 0s 452us/sample - loss: 0.3353 - accuracy: 0.9404\n","Epoch 295/500\n","453/453 [==============================] - 0s 450us/sample - loss: 0.3330 - accuracy: 0.9382\n","Epoch 296/500\n","453/453 [==============================] - 0s 442us/sample - loss: 0.3300 - accuracy: 0.9404\n","Epoch 297/500\n","453/453 [==============================] - 0s 444us/sample - loss: 0.3282 - accuracy: 0.9404\n","Epoch 298/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.3262 - accuracy: 0.9426\n","Epoch 299/500\n","453/453 [==============================] - 0s 430us/sample - loss: 0.3237 - accuracy: 0.9426\n","Epoch 300/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.3222 - accuracy: 0.9360\n","Epoch 301/500\n","453/453 [==============================] - 0s 440us/sample - loss: 0.3204 - accuracy: 0.9382\n","Epoch 302/500\n","453/453 [==============================] - 0s 461us/sample - loss: 0.3174 - accuracy: 0.9404\n","Epoch 303/500\n","453/453 [==============================] - 0s 422us/sample - loss: 0.3163 - accuracy: 0.9382\n","Epoch 304/500\n","453/453 [==============================] - 0s 426us/sample - loss: 0.3147 - accuracy: 0.9426\n","Epoch 305/500\n","453/453 [==============================] - 0s 442us/sample - loss: 0.3127 - accuracy: 0.9448\n","Epoch 306/500\n","453/453 [==============================] - 0s 435us/sample - loss: 0.3107 - accuracy: 0.9448\n","Epoch 307/500\n","453/453 [==============================] - 0s 433us/sample - loss: 0.3083 - accuracy: 0.9426\n","Epoch 308/500\n","453/453 [==============================] - 0s 446us/sample - loss: 0.3072 - accuracy: 0.9426\n","Epoch 309/500\n","453/453 [==============================] - 0s 417us/sample - loss: 0.3056 - accuracy: 0.9448\n","Epoch 310/500\n","453/453 [==============================] - 0s 437us/sample - loss: 0.3039 - accuracy: 0.9426\n","Epoch 311/500\n","453/453 [==============================] - 0s 448us/sample - loss: 0.3005 - accuracy: 0.9426\n","Epoch 312/500\n","453/453 [==============================] - 0s 425us/sample - loss: 0.2966 - accuracy: 0.9448\n","Epoch 313/500\n","453/453 [==============================] - 0s 453us/sample - loss: 0.2944 - accuracy: 0.9448\n","Epoch 314/500\n","453/453 [==============================] - 0s 436us/sample - loss: 0.2921 - accuracy: 0.9448\n","Epoch 315/500\n","453/453 [==============================] - 0s 438us/sample - loss: 0.2904 - accuracy: 0.9448\n","Epoch 316/500\n","453/453 [==============================] - 0s 444us/sample - loss: 0.2885 - accuracy: 0.9426\n","Epoch 317/500\n","453/453 [==============================] - 0s 443us/sample - loss: 0.2873 - accuracy: 0.9448\n","Epoch 318/500\n","453/453 [==============================] - 0s 439us/sample - loss: 0.2864 - accuracy: 0.9426\n","Epoch 319/500\n","453/453 [==============================] - 0s 429us/sample - loss: 0.2848 - accuracy: 0.9448\n","Epoch 320/500\n","453/453 [==============================] - 0s 448us/sample - loss: 0.2838 - accuracy: 0.9426\n","Epoch 321/500\n","453/453 [==============================] - 0s 439us/sample - loss: 0.2811 - accuracy: 0.9448\n","Epoch 322/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.2880 - accuracy: 0.9382\n","Epoch 323/500\n","453/453 [==============================] - 0s 451us/sample - loss: 0.2851 - accuracy: 0.9404\n","Epoch 324/500\n","453/453 [==============================] - 0s 440us/sample - loss: 0.2871 - accuracy: 0.9360\n","Epoch 325/500\n","453/453 [==============================] - 0s 445us/sample - loss: 0.2868 - accuracy: 0.9360\n","Epoch 326/500\n","453/453 [==============================] - 0s 431us/sample - loss: 0.2834 - accuracy: 0.9382\n","Epoch 327/500\n","453/453 [==============================] - 0s 444us/sample - loss: 0.2746 - accuracy: 0.9426\n","Epoch 328/500\n","453/453 [==============================] - 0s 473us/sample - loss: 0.3100 - accuracy: 0.9360\n","Epoch 329/500\n","453/453 [==============================] - 0s 449us/sample - loss: 0.3092 - accuracy: 0.9382\n","Epoch 330/500\n","453/453 [==============================] - 0s 439us/sample - loss: 0.3130 - accuracy: 0.9360\n","Epoch 331/500\n","453/453 [==============================] - 0s 438us/sample - loss: 0.3163 - accuracy: 0.9272\n","Epoch 332/500\n","453/453 [==============================] - 0s 445us/sample - loss: 0.3314 - accuracy: 0.9272\n","Epoch 333/500\n","453/453 [==============================] - 0s 456us/sample - loss: 0.3207 - accuracy: 0.9272\n","Epoch 334/500\n","453/453 [==============================] - 0s 452us/sample - loss: 0.3003 - accuracy: 0.9338\n","Epoch 335/500\n","453/453 [==============================] - 0s 445us/sample - loss: 0.2976 - accuracy: 0.9316\n","Epoch 336/500\n","453/453 [==============================] - 0s 462us/sample - loss: 0.3026 - accuracy: 0.9338\n","Epoch 337/500\n","453/453 [==============================] - 0s 451us/sample - loss: 0.3075 - accuracy: 0.9360\n","Epoch 338/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.2982 - accuracy: 0.9294\n","Epoch 339/500\n","453/453 [==============================] - 0s 440us/sample - loss: 0.2939 - accuracy: 0.9404\n","Epoch 340/500\n","453/453 [==============================] - 0s 449us/sample - loss: 0.2970 - accuracy: 0.9338\n","Epoch 341/500\n","453/453 [==============================] - 0s 437us/sample - loss: 0.2876 - accuracy: 0.9338\n","Epoch 342/500\n","453/453 [==============================] - 0s 447us/sample - loss: 0.2744 - accuracy: 0.9404\n","Epoch 343/500\n","453/453 [==============================] - 0s 430us/sample - loss: 0.2695 - accuracy: 0.9426\n","Epoch 344/500\n","453/453 [==============================] - 0s 466us/sample - loss: 0.2710 - accuracy: 0.9404\n","Epoch 345/500\n","453/453 [==============================] - 0s 436us/sample - loss: 0.2650 - accuracy: 0.9426\n","Epoch 346/500\n","453/453 [==============================] - 0s 461us/sample - loss: 0.2549 - accuracy: 0.9426\n","Epoch 347/500\n","453/453 [==============================] - 0s 466us/sample - loss: 0.2506 - accuracy: 0.9448\n","Epoch 348/500\n","453/453 [==============================] - 0s 456us/sample - loss: 0.2511 - accuracy: 0.9404\n","Epoch 349/500\n","453/453 [==============================] - 0s 442us/sample - loss: 0.2480 - accuracy: 0.9470\n","Epoch 350/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.2425 - accuracy: 0.9448\n","Epoch 351/500\n","453/453 [==============================] - 0s 446us/sample - loss: 0.2459 - accuracy: 0.9448\n","Epoch 352/500\n","453/453 [==============================] - 0s 465us/sample - loss: 0.2423 - accuracy: 0.9426\n","Epoch 353/500\n","453/453 [==============================] - 0s 429us/sample - loss: 0.2398 - accuracy: 0.9404\n","Epoch 354/500\n","453/453 [==============================] - 0s 445us/sample - loss: 0.2368 - accuracy: 0.9492\n","Epoch 355/500\n","453/453 [==============================] - 0s 440us/sample - loss: 0.2347 - accuracy: 0.9492\n","Epoch 356/500\n","453/453 [==============================] - 0s 448us/sample - loss: 0.2335 - accuracy: 0.9470\n","Epoch 357/500\n","453/453 [==============================] - 0s 437us/sample - loss: 0.2316 - accuracy: 0.9470\n","Epoch 358/500\n","453/453 [==============================] - 0s 430us/sample - loss: 0.2312 - accuracy: 0.9514\n","Epoch 359/500\n","453/453 [==============================] - 0s 430us/sample - loss: 0.2289 - accuracy: 0.9492\n","Epoch 360/500\n","453/453 [==============================] - 0s 455us/sample - loss: 0.2278 - accuracy: 0.9470\n","Epoch 361/500\n","453/453 [==============================] - 0s 461us/sample - loss: 0.2273 - accuracy: 0.9448\n","Epoch 362/500\n","453/453 [==============================] - 0s 433us/sample - loss: 0.2257 - accuracy: 0.9448\n","Epoch 363/500\n","453/453 [==============================] - 0s 439us/sample - loss: 0.2231 - accuracy: 0.9470\n","Epoch 364/500\n","453/453 [==============================] - 0s 445us/sample - loss: 0.2220 - accuracy: 0.9492\n","Epoch 365/500\n","453/453 [==============================] - 0s 454us/sample - loss: 0.2212 - accuracy: 0.9448\n","Epoch 366/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.2198 - accuracy: 0.9492\n","Epoch 367/500\n","453/453 [==============================] - 0s 443us/sample - loss: 0.2200 - accuracy: 0.9492\n","Epoch 368/500\n","453/453 [==============================] - 0s 442us/sample - loss: 0.2172 - accuracy: 0.9470\n","Epoch 369/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.2172 - accuracy: 0.9470\n","Epoch 370/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.2159 - accuracy: 0.9492\n","Epoch 371/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.2155 - accuracy: 0.9492\n","Epoch 372/500\n","453/453 [==============================] - 0s 445us/sample - loss: 0.2147 - accuracy: 0.9492\n","Epoch 373/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.2133 - accuracy: 0.9492\n","Epoch 374/500\n","453/453 [==============================] - 0s 444us/sample - loss: 0.2116 - accuracy: 0.9492\n","Epoch 375/500\n","453/453 [==============================] - 0s 437us/sample - loss: 0.2102 - accuracy: 0.9470\n","Epoch 376/500\n","453/453 [==============================] - 0s 449us/sample - loss: 0.2094 - accuracy: 0.9492\n","Epoch 377/500\n","453/453 [==============================] - 0s 429us/sample - loss: 0.2097 - accuracy: 0.9492\n","Epoch 378/500\n","453/453 [==============================] - 0s 443us/sample - loss: 0.2080 - accuracy: 0.9492\n","Epoch 379/500\n","453/453 [==============================] - 0s 434us/sample - loss: 0.2065 - accuracy: 0.9470\n","Epoch 380/500\n","453/453 [==============================] - 0s 507us/sample - loss: 0.2049 - accuracy: 0.9514\n","Epoch 381/500\n","453/453 [==============================] - 0s 442us/sample - loss: 0.2038 - accuracy: 0.9514\n","Epoch 382/500\n","453/453 [==============================] - 0s 435us/sample - loss: 0.2033 - accuracy: 0.9492\n","Epoch 383/500\n","453/453 [==============================] - 0s 413us/sample - loss: 0.2025 - accuracy: 0.9492\n","Epoch 384/500\n","453/453 [==============================] - 0s 440us/sample - loss: 0.2018 - accuracy: 0.9514\n","Epoch 385/500\n","453/453 [==============================] - 0s 433us/sample - loss: 0.2012 - accuracy: 0.9492\n","Epoch 386/500\n","453/453 [==============================] - 0s 458us/sample - loss: 0.2002 - accuracy: 0.9470\n","Epoch 387/500\n","453/453 [==============================] - 0s 453us/sample - loss: 0.1988 - accuracy: 0.9492\n","Epoch 388/500\n","453/453 [==============================] - 0s 452us/sample - loss: 0.1993 - accuracy: 0.9514\n","Epoch 389/500\n","453/453 [==============================] - 0s 437us/sample - loss: 0.1968 - accuracy: 0.9514\n","Epoch 390/500\n","453/453 [==============================] - 0s 442us/sample - loss: 0.1972 - accuracy: 0.9492\n","Epoch 391/500\n","453/453 [==============================] - 0s 439us/sample - loss: 0.1960 - accuracy: 0.9514\n","Epoch 392/500\n","453/453 [==============================] - 0s 440us/sample - loss: 0.1949 - accuracy: 0.9492\n","Epoch 393/500\n","453/453 [==============================] - 0s 446us/sample - loss: 0.1931 - accuracy: 0.9448\n","Epoch 394/500\n","453/453 [==============================] - 0s 448us/sample - loss: 0.1918 - accuracy: 0.9492\n","Epoch 395/500\n","453/453 [==============================] - 0s 443us/sample - loss: 0.1918 - accuracy: 0.9514\n","Epoch 396/500\n","453/453 [==============================] - 0s 435us/sample - loss: 0.1909 - accuracy: 0.9470\n","Epoch 397/500\n","453/453 [==============================] - 0s 443us/sample - loss: 0.1922 - accuracy: 0.9448\n","Epoch 398/500\n","453/453 [==============================] - 0s 430us/sample - loss: 0.1890 - accuracy: 0.9492\n","Epoch 399/500\n","453/453 [==============================] - 0s 433us/sample - loss: 0.1878 - accuracy: 0.9514\n","Epoch 400/500\n","453/453 [==============================] - 0s 444us/sample - loss: 0.1870 - accuracy: 0.9470\n","Epoch 401/500\n","453/453 [==============================] - 0s 438us/sample - loss: 0.1862 - accuracy: 0.9470\n","Epoch 402/500\n","453/453 [==============================] - 0s 449us/sample - loss: 0.1856 - accuracy: 0.9448\n","Epoch 403/500\n","453/453 [==============================] - 0s 443us/sample - loss: 0.1849 - accuracy: 0.9470\n","Epoch 404/500\n","453/453 [==============================] - 0s 439us/sample - loss: 0.1836 - accuracy: 0.9492\n","Epoch 405/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.1832 - accuracy: 0.9426\n","Epoch 406/500\n","453/453 [==============================] - 0s 449us/sample - loss: 0.1822 - accuracy: 0.9448\n","Epoch 407/500\n","453/453 [==============================] - 0s 442us/sample - loss: 0.1822 - accuracy: 0.9492\n","Epoch 408/500\n","453/453 [==============================] - 0s 439us/sample - loss: 0.1824 - accuracy: 0.9470\n","Epoch 409/500\n","453/453 [==============================] - 0s 448us/sample - loss: 0.1811 - accuracy: 0.9448\n","Epoch 410/500\n","453/453 [==============================] - 0s 443us/sample - loss: 0.1790 - accuracy: 0.9448\n","Epoch 411/500\n","453/453 [==============================] - 0s 443us/sample - loss: 0.1782 - accuracy: 0.9448\n","Epoch 412/500\n","453/453 [==============================] - 0s 455us/sample - loss: 0.1771 - accuracy: 0.9492\n","Epoch 413/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.1763 - accuracy: 0.9492\n","Epoch 414/500\n","453/453 [==============================] - 0s 428us/sample - loss: 0.1752 - accuracy: 0.9492\n","Epoch 415/500\n","453/453 [==============================] - 0s 444us/sample - loss: 0.1745 - accuracy: 0.9470\n","Epoch 416/500\n","453/453 [==============================] - 0s 437us/sample - loss: 0.1738 - accuracy: 0.9492\n","Epoch 417/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.1729 - accuracy: 0.9492\n","Epoch 418/500\n","453/453 [==============================] - 0s 438us/sample - loss: 0.1726 - accuracy: 0.9426\n","Epoch 419/500\n","453/453 [==============================] - 0s 448us/sample - loss: 0.1718 - accuracy: 0.9448\n","Epoch 420/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.1710 - accuracy: 0.9470\n","Epoch 421/500\n","453/453 [==============================] - 0s 461us/sample - loss: 0.1709 - accuracy: 0.9448\n","Epoch 422/500\n","453/453 [==============================] - 0s 459us/sample - loss: 0.1698 - accuracy: 0.9448\n","Epoch 423/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.1696 - accuracy: 0.9448\n","Epoch 424/500\n","453/453 [==============================] - 0s 439us/sample - loss: 0.1685 - accuracy: 0.9470\n","Epoch 425/500\n","453/453 [==============================] - 0s 447us/sample - loss: 0.1672 - accuracy: 0.9514\n","Epoch 426/500\n","453/453 [==============================] - 0s 449us/sample - loss: 0.1674 - accuracy: 0.9470\n","Epoch 427/500\n","453/453 [==============================] - 0s 443us/sample - loss: 0.1673 - accuracy: 0.9514\n","Epoch 428/500\n","453/453 [==============================] - 0s 458us/sample - loss: 0.1668 - accuracy: 0.9492\n","Epoch 429/500\n","453/453 [==============================] - 0s 446us/sample - loss: 0.1657 - accuracy: 0.9514\n","Epoch 430/500\n","453/453 [==============================] - 0s 446us/sample - loss: 0.1645 - accuracy: 0.9448\n","Epoch 431/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.1636 - accuracy: 0.9536\n","Epoch 432/500\n","453/453 [==============================] - 0s 445us/sample - loss: 0.1634 - accuracy: 0.9514\n","Epoch 433/500\n","453/453 [==============================] - 0s 440us/sample - loss: 0.1628 - accuracy: 0.9536\n","Epoch 434/500\n","453/453 [==============================] - 0s 444us/sample - loss: 0.1624 - accuracy: 0.9514\n","Epoch 435/500\n","453/453 [==============================] - 0s 469us/sample - loss: 0.1620 - accuracy: 0.9470\n","Epoch 436/500\n","453/453 [==============================] - 0s 440us/sample - loss: 0.1622 - accuracy: 0.9536\n","Epoch 437/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.1622 - accuracy: 0.9492\n","Epoch 438/500\n","453/453 [==============================] - 0s 409us/sample - loss: 0.1616 - accuracy: 0.9492\n","Epoch 439/500\n","453/453 [==============================] - 0s 445us/sample - loss: 0.1685 - accuracy: 0.9492\n","Epoch 440/500\n","453/453 [==============================] - 0s 438us/sample - loss: 0.1703 - accuracy: 0.9448\n","Epoch 441/500\n","453/453 [==============================] - 0s 443us/sample - loss: 0.1768 - accuracy: 0.9448\n","Epoch 442/500\n","453/453 [==============================] - 0s 428us/sample - loss: 0.1908 - accuracy: 0.9404\n","Epoch 443/500\n","453/453 [==============================] - 0s 442us/sample - loss: 0.2669 - accuracy: 0.9249\n","Epoch 444/500\n","453/453 [==============================] - 0s 452us/sample - loss: 0.2265 - accuracy: 0.9382\n","Epoch 445/500\n","453/453 [==============================] - 0s 448us/sample - loss: 0.2457 - accuracy: 0.9338\n","Epoch 446/500\n","453/453 [==============================] - 0s 432us/sample - loss: 0.2987 - accuracy: 0.9139\n","Epoch 447/500\n","453/453 [==============================] - 0s 440us/sample - loss: 0.2806 - accuracy: 0.9183\n","Epoch 448/500\n","453/453 [==============================] - 0s 445us/sample - loss: 0.2858 - accuracy: 0.9205\n","Epoch 449/500\n","453/453 [==============================] - 0s 478us/sample - loss: 0.2446 - accuracy: 0.9404\n","Epoch 450/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.2280 - accuracy: 0.9404\n","Epoch 451/500\n","453/453 [==============================] - 0s 446us/sample - loss: 0.1920 - accuracy: 0.9448\n","Epoch 452/500\n","453/453 [==============================] - 0s 444us/sample - loss: 0.1844 - accuracy: 0.9470\n","Epoch 453/500\n","453/453 [==============================] - 0s 438us/sample - loss: 0.1741 - accuracy: 0.9492\n","Epoch 454/500\n","453/453 [==============================] - 0s 443us/sample - loss: 0.1704 - accuracy: 0.9514\n","Epoch 455/500\n","453/453 [==============================] - 0s 439us/sample - loss: 0.1669 - accuracy: 0.9514\n","Epoch 456/500\n","453/453 [==============================] - 0s 432us/sample - loss: 0.1635 - accuracy: 0.9536\n","Epoch 457/500\n","453/453 [==============================] - 0s 436us/sample - loss: 0.1624 - accuracy: 0.9492\n","Epoch 458/500\n","453/453 [==============================] - 0s 445us/sample - loss: 0.1602 - accuracy: 0.9514\n","Epoch 459/500\n","453/453 [==============================] - 0s 433us/sample - loss: 0.1594 - accuracy: 0.9514\n","Epoch 460/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.1579 - accuracy: 0.9514\n","Epoch 461/500\n","453/453 [==============================] - 0s 444us/sample - loss: 0.1567 - accuracy: 0.9470\n","Epoch 462/500\n","453/453 [==============================] - 0s 447us/sample - loss: 0.1556 - accuracy: 0.9470\n","Epoch 463/500\n","453/453 [==============================] - 0s 443us/sample - loss: 0.1540 - accuracy: 0.9448\n","Epoch 464/500\n","453/453 [==============================] - 0s 442us/sample - loss: 0.1540 - accuracy: 0.9470\n","Epoch 465/500\n","453/453 [==============================] - 0s 444us/sample - loss: 0.1528 - accuracy: 0.9448\n","Epoch 466/500\n","453/453 [==============================] - 0s 437us/sample - loss: 0.1525 - accuracy: 0.9470\n","Epoch 467/500\n","453/453 [==============================] - 0s 447us/sample - loss: 0.1513 - accuracy: 0.9492\n","Epoch 468/500\n","453/453 [==============================] - 0s 442us/sample - loss: 0.1508 - accuracy: 0.9470\n","Epoch 469/500\n","453/453 [==============================] - 0s 433us/sample - loss: 0.1496 - accuracy: 0.9470\n","Epoch 470/500\n","453/453 [==============================] - 0s 449us/sample - loss: 0.1499 - accuracy: 0.9492\n","Epoch 471/500\n","453/453 [==============================] - 0s 438us/sample - loss: 0.1486 - accuracy: 0.9514\n","Epoch 472/500\n","453/453 [==============================] - 0s 446us/sample - loss: 0.1476 - accuracy: 0.9492\n","Epoch 473/500\n","453/453 [==============================] - 0s 453us/sample - loss: 0.1475 - accuracy: 0.9492\n","Epoch 474/500\n","453/453 [==============================] - 0s 448us/sample - loss: 0.1465 - accuracy: 0.9470\n","Epoch 475/500\n","453/453 [==============================] - 0s 449us/sample - loss: 0.1457 - accuracy: 0.9514\n","Epoch 476/500\n","453/453 [==============================] - 0s 447us/sample - loss: 0.1448 - accuracy: 0.9514\n","Epoch 477/500\n","453/453 [==============================] - 0s 431us/sample - loss: 0.1439 - accuracy: 0.9470\n","Epoch 478/500\n","453/453 [==============================] - 0s 442us/sample - loss: 0.1435 - accuracy: 0.9492\n","Epoch 479/500\n","453/453 [==============================] - 0s 472us/sample - loss: 0.1436 - accuracy: 0.9514\n","Epoch 480/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.1442 - accuracy: 0.9514\n","Epoch 481/500\n","453/453 [==============================] - 0s 447us/sample - loss: 0.1445 - accuracy: 0.9470\n","Epoch 482/500\n","453/453 [==============================] - 0s 443us/sample - loss: 0.1433 - accuracy: 0.9492\n","Epoch 483/500\n","453/453 [==============================] - 0s 427us/sample - loss: 0.1420 - accuracy: 0.9514\n","Epoch 484/500\n","453/453 [==============================] - 0s 426us/sample - loss: 0.1414 - accuracy: 0.9492\n","Epoch 485/500\n","453/453 [==============================] - 0s 436us/sample - loss: 0.1407 - accuracy: 0.9470\n","Epoch 486/500\n","453/453 [==============================] - 0s 446us/sample - loss: 0.1396 - accuracy: 0.9492\n","Epoch 487/500\n","453/453 [==============================] - 0s 426us/sample - loss: 0.1397 - accuracy: 0.9492\n","Epoch 488/500\n","453/453 [==============================] - 0s 465us/sample - loss: 0.1399 - accuracy: 0.9448\n","Epoch 489/500\n","453/453 [==============================] - 0s 437us/sample - loss: 0.1410 - accuracy: 0.9492\n","Epoch 490/500\n","453/453 [==============================] - 0s 434us/sample - loss: 0.1402 - accuracy: 0.9470\n","Epoch 491/500\n","453/453 [==============================] - 0s 448us/sample - loss: 0.1386 - accuracy: 0.9492\n","Epoch 492/500\n","453/453 [==============================] - 0s 445us/sample - loss: 0.1376 - accuracy: 0.9514\n","Epoch 493/500\n","453/453 [==============================] - 0s 456us/sample - loss: 0.1371 - accuracy: 0.9470\n","Epoch 494/500\n","453/453 [==============================] - 0s 439us/sample - loss: 0.1364 - accuracy: 0.9426\n","Epoch 495/500\n","453/453 [==============================] - 0s 448us/sample - loss: 0.1361 - accuracy: 0.9492\n","Epoch 496/500\n","453/453 [==============================] - 0s 450us/sample - loss: 0.1358 - accuracy: 0.9492\n","Epoch 497/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.1351 - accuracy: 0.9426\n","Epoch 498/500\n","453/453 [==============================] - 0s 441us/sample - loss: 0.1349 - accuracy: 0.9404\n","Epoch 499/500\n","453/453 [==============================] - 0s 419us/sample - loss: 0.1344 - accuracy: 0.9448\n","Epoch 500/500\n","453/453 [==============================] - 0s 498us/sample - loss: 0.1341 - accuracy: 0.9470\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sa6nymoqPSY6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"outputId":"cf19c523-323f-4f01-c997-3f10afd62a4d","executionInfo":{"status":"ok","timestamp":1579209906330,"user_tz":480,"elapsed":463,"user":{"displayName":"Hieu Quoc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBXboZp2dMx_so4JiaOdf8YR1jpP73S07Pde39vvw=s64","userId":"07041430737003441740"}}},"source":["model.summary()"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 10, 64)            16832     \n","_________________________________________________________________\n","bidirectional (Bidirectional (None, 40)                13600     \n","_________________________________________________________________\n","dense (Dense)                (None, 263)               10783     \n","=================================================================\n","Total params: 41,215\n","Trainable params: 41,215\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Nlusw3IdO2VQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":283},"outputId":"9d646190-7120-41dd-fd44-9d1d03c5758e","executionInfo":{"status":"ok","timestamp":1579209914323,"user_tz":480,"elapsed":478,"user":{"displayName":"Hieu Quoc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBXboZp2dMx_so4JiaOdf8YR1jpP73S07Pde39vvw=s64","userId":"07041430737003441740"}}},"source":["import matplotlib.pyplot as plt\n","\n","\n","def plot_graphs(history, string):\n","  plt.plot(history.history[string])\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(string)\n","  plt.show()\n","\n","plot_graphs(history, 'accuracy')"],"execution_count":18,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"CcEPEo2pO88_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"a682356a-558f-49c5-b96f-158b83c3f24d","executionInfo":{"status":"ok","timestamp":1579209920279,"user_tz":480,"elapsed":1691,"user":{"displayName":"Hieu Quoc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBXboZp2dMx_so4JiaOdf8YR1jpP73S07Pde39vvw=s64","userId":"07041430737003441740"}}},"source":["seed_text = \"Laurence went to dublin\"\n","next_words = 100\n","  \n","for _ in range(next_words): # for each of the next 100 words\n","  # create a token list based on the seed text\n","\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n","  # That token list will be pre padded to the desired length\n","\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","  # pass that padded token list into the model\n","\tpredicted = model.predict_classes(token_list, verbose=0)\n","\toutput_word = \"\"\n","  # Keep take the prediction output and keep feeding it into the model\n","  # This piece of code does a reverse lookup on the word index items\n","  # to turn a token back into a word, then add it to our seed text\n","\tfor word, index in tokenizer.word_index.items():\n","\t\tif index == predicted:\n","\t\t\toutput_word = word\n","\t\t\tbreak\n","\tseed_text += \" \" + output_word\n","print(seed_text)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Laurence went to dublin girls the same time as red as as table ground ground under as groups girls me ned glisten suppose suppose suppose ground steps at them me time at table table under a rose had ground ground table steps all entangled at table ground ground under a red as entangled saw cheeks entangled me entangled entangled saw friends me and tea ground ned glisten ladies table tea suppose ned friends and tea tea ned glisten hoops tea able able relations friends and tea tea ned ask ask suppose tea tea relations tea tea friends and ground ground ground ground ground ground\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uLt1_im5QzCA","colab_type":"text"},"source":["- WITHOUT BI DIRECTIONAL LSTM: this measn that LSTM only carries the context FWD. This will result in a lot of REPETITION word on the prediction. Bi directional converges a lot faster than regular LSTM\n","\n","- We can see what's actually happening here is that in the beginning it kind of looks pretty good. It's beginning to make sense. But of course because our body of texts is pretty small and each prediction is a probability.\n","\n","- But as you can see then, as you get further and further and further then the probabilities are decreasing and the quality of the prediction as a result goes down. So you end up with for example repeated words like Jake Jake, gathered gathered."]},{"cell_type":"code","metadata":{"id":"wsY9Pg4UPwfF","colab_type":"code","colab":{}},"source":["import os, signal\n","os.kill(os.getpid(), signal.SIGKILL)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JvCyGt5cRHrK","colab_type":"text"},"source":["# LECTURE 2:"]},{"cell_type":"code","metadata":{"id":"rUzZxwa6SALL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"88967b55-fa8a-437c-e995-4283b14f4583","executionInfo":{"status":"ok","timestamp":1579210547221,"user_tz":480,"elapsed":2702,"user":{"displayName":"Hieu Quoc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBXboZp2dMx_so4JiaOdf8YR1jpP73S07Pde39vvw=s64","userId":"07041430737003441740"}}},"source":["# get bigger data\n","!wget --no-check-certificate \\\n","    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/irish-lyrics-eof.txt \\\n","    -O /tmp/irish-lyrics-eof.txt"],"execution_count":6,"outputs":[{"output_type":"stream","text":["--2020-01-16 21:35:45--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/irish-lyrics-eof.txt\n","Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.119.128, 2a00:1450:4013:c01::80\n","Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.119.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 68970 (67K) [text/plain]\n","Saving to: ‘/tmp/irish-lyrics-eof.txt’\n","\n","/tmp/irish-lyrics-e 100%[===================>]  67.35K  --.-KB/s    in 0.001s  \n","\n","2020-01-16 21:35:46 (131 MB/s) - ‘/tmp/irish-lyrics-eof.txt’ saved [68970/68970]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TxqXD3-vSMYK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"dffef288-3644-49a5-bfd7-f32ba4faab8f","executionInfo":{"status":"ok","timestamp":1579210587725,"user_tz":480,"elapsed":554,"user":{"displayName":"Hieu Quoc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBXboZp2dMx_so4JiaOdf8YR1jpP73S07Pde39vvw=s64","userId":"07041430737003441740"}}},"source":["tokenizer = Tokenizer()\n","\n","data = open('/tmp/irish-lyrics-eof.txt').read()\n","\n","corpus = data.lower().split(\"\\n\")\n","\n","tokenizer.fit_on_texts(corpus)\n","total_words = len(tokenizer.word_index) + 1\n","\n","print(tokenizer.word_index)\n","print(total_words) # lots bigger corpus to train on"],"execution_count":9,"outputs":[{"output_type":"stream","text":["{'the': 1, 'and': 2, 'i': 3, 'to': 4, 'a': 5, 'of': 6, 'my': 7, 'in': 8, 'me': 9, 'for': 10, 'you': 11, 'all': 12, 'was': 13, 'she': 14, 'that': 15, 'on': 16, 'with': 17, 'her': 18, 'but': 19, 'as': 20, 'when': 21, 'love': 22, 'is': 23, 'your': 24, 'it': 25, 'will': 26, 'from': 27, 'by': 28, 'they': 29, 'be': 30, 'are': 31, 'so': 32, 'he': 33, 'old': 34, 'no': 35, 'oh': 36, 'ill': 37, 'at': 38, 'one': 39, 'his': 40, 'there': 41, 'were': 42, 'heart': 43, 'down': 44, 'now': 45, 'we': 46, 'where': 47, 'young': 48, 'never': 49, 'go': 50, 'come': 51, 'then': 52, 'did': 53, 'not': 54, 'said': 55, 'away': 56, 'their': 57, 'sweet': 58, 'them': 59, 'green': 60, 'if': 61, 'take': 62, 'our': 63, 'like': 64, 'night': 65, 'day': 66, 'o': 67, 'out': 68, 'fair': 69, 'this': 70, 'town': 71, 'have': 72, 'can': 73, 'true': 74, 'its': 75, 'thou': 76, 'see': 77, 'dear': 78, 'more': 79, 'theres': 80, 'or': 81, 'had': 82, 'would': 83, 'over': 84, 'hear': 85, 'up': 86, 'ive': 87, 'through': 88, 'home': 89, 'again': 90, 'well': 91, 'oer': 92, 'land': 93, 'good': 94, 'im': 95, 'ye': 96, 'sea': 97, 'left': 98, 'still': 99, 'father': 100, 'long': 101, 'rose': 102, 'could': 103, 'morning': 104, 'wild': 105, 'who': 106, 'eyes': 107, 'came': 108, 'while': 109, 'too': 110, 'back': 111, 'little': 112, 'an': 113, 'took': 114, 'him': 115, 'bow': 116, 'first': 117, 'let': 118, 'man': 119, 'shall': 120, 'know': 121, 'get': 122, 'high': 123, 'gone': 124, 'say': 125, 'ever': 126, 'some': 127, 'mary': 128, 'hand': 129, 'till': 130, 'put': 131, 'own': 132, 'time': 133, 'heard': 134, 'dead': 135, 'may': 136, 'bright': 137, 'mountain': 138, 'early': 139, 'rosin': 140, 'gave': 141, 'thee': 142, 'only': 143, 'far': 144, 'maid': 145, 'must': 146, 'find': 147, 'girl': 148, 'sure': 149, 'round': 150, 'dublin': 151, 'once': 152, 'world': 153, 'delight': 154, 'last': 155, 'johnny': 156, 'seen': 157, 'has': 158, 'fine': 159, 'road': 160, 'mother': 161, 'tis': 162, 'what': 163, 'way': 164, 'moon': 165, 'soul': 166, 'neer': 167, 'id': 168, 'just': 169, 'thats': 170, 'days': 171, 'darling': 172, 'went': 173, 'white': 174, 'die': 175, 'than': 176, 'hair': 177, 'goes': 178, 'meet': 179, 'today': 180, 'do': 181, 'girls': 182, 'shes': 183, 'thyme': 184, 'thy': 185, 'sing': 186, 'pretty': 187, 'new': 188, 'poor': 189, 'into': 190, 'life': 191, 'irish': 192, 'give': 193, 'boy': 194, 'youre': 195, 'make': 196, 'passed': 197, 'lovely': 198, 'black': 199, 'youll': 200, 'died': 201, 'red': 202, 'smile': 203, 'keep': 204, 'loves': 205, 'free': 206, 'leave': 207, 'friends': 208, 'each': 209, 'saw': 210, 'behind': 211, 'song': 212, 'ra': 213, 'dont': 214, 'arms': 215, 'am': 216, 'sun': 217, 'saying': 218, 'made': 219, 'wish': 220, 'cold': 221, 'met': 222, 'before': 223, 'should': 224, 'rocky': 225, 'light': 226, 'wid': 227, 'boys': 228, 'best': 229, 'fields': 230, 'since': 231, 'ball': 232, 'water': 233, 'casey': 234, 'mind': 235, 'along': 236, 'loved': 237, 'place': 238, 'ireland': 239, 'next': 240, 'three': 241, 'many': 242, 'years': 243, 'door': 244, 'us': 245, 'drink': 246, 'got': 247, 'might': 248, 'live': 249, 'roses': 250, 'play': 251, 'soon': 252, 'ground': 253, 'times': 254, 'spent': 255, 'going': 256, 'tree': 257, 'barley': 258, 'grass': 259, 'kind': 260, 'twas': 261, 'bridge': 262, 'around': 263, 'blue': 264, 'tell': 265, 'row': 266, 'how': 267, 'money': 268, 'merry': 269, 'stepped': 270, 'corporal': 271, 'always': 272, 'though': 273, 'near': 274, 'taken': 275, 'ones': 276, 'daughter': 277, 'forever': 278, 'loo': 279, 'shining': 280, 'plenty': 281, 'hes': 282, 'ship': 283, 'banks': 284, 'think': 285, 'very': 286, 'stand': 287, 'heres': 288, 'snow': 289, 'mountains': 290, 'molly': 291, 'wheel': 292, 'street': 293, 'erin': 294, 'side': 295, 'feet': 296, 'star': 297, 'look': 298, 'brave': 299, 'woman': 300, 'sons': 301, 'two': 302, 'says': 303, 'asked': 304, 'lanigans': 305, 'singing': 306, 'men': 307, 'toome': 308, 'stole': 309, 'god': 310, 'hill': 311, 'lonely': 312, 'lover': 313, 'tears': 314, 'fathers': 315, 'low': 316, 'voice': 317, 'quite': 318, 'able': 319, 'nice': 320, 'laid': 321, 'comrades': 322, 'wind': 323, 'another': 324, 'sit': 325, 'face': 326, 'band': 327, 'call': 328, 'colleen': 329, 'until': 330, 'hills': 331, 'mine': 332, 'above': 333, 'upon': 334, 'eer': 335, 'youve': 336, 'fly': 337, 'been': 338, 'late': 339, 'alive': 340, 'ballyjamesduff': 341, 'looked': 342, 'great': 343, 'why': 344, 'every': 345, 'proud': 346, 'found': 347, 'bragh': 348, 'such': 349, 'birds': 350, 'wedding': 351, 'welcome': 352, 'dancing': 353, 'da': 354, 'fell': 355, 'thinking': 356, 'roddy': 357, 'mccorley': 358, 'smiling': 359, 'mallow': 360, 'blooming': 361, 'thought': 362, 'peace': 363, 'soft': 364, 'pure': 365, 'harp': 366, 'dream': 367, 'alas': 368, 'yet': 369, 'clear': 370, 'art': 371, 'off': 372, 'hope': 373, 'fought': 374, 'mothers': 375, 'shore': 376, 'ago': 377, 'fol': 378, 'de': 379, 'house': 380, 'married': 381, 'bound': 382, 'danced': 383, 'devil': 384, 'dawning': 385, 'makes': 386, 'same': 387, 'sat': 388, 'any': 389, 'glass': 390, 'gay': 391, 'relations': 392, 'evening': 393, 'watched': 394, 'right': 395, 'fellows': 396, 'whiskey': 397, 'bonnie': 398, 'grows': 399, 'women': 400, 'flowers': 401, 'beauty': 402, 'cannot': 403, 'handsome': 404, 'happy': 405, 'gold': 406, 'rover': 407, 'none': 408, 'doneen': 409, 'summers': 410, 'people': 411, 'set': 412, 'paddy': 413, 'morn': 414, 'most': 415, 'easy': 416, 'struck': 417, 'beautiful': 418, 'those': 419, 'golden': 420, 'run': 421, 'pipes': 422, 'glen': 423, 'dying': 424, 'here': 425, 'wall': 426, 'across': 427, 'fire': 428, 'eileen': 429, 'longer': 430, 'cheeks': 431, 'valley': 432, 'both': 433, 'dew': 434, 'care': 435, 'bride': 436, 'nothing': 437, 'wont': 438, 'theyre': 439, 'colonel': 440, 'maiden': 441, 'shed': 442, 'til': 443, 'brown': 444, 'breast': 445, 'corn': 446, 'sinking': 447, 'began': 448, 'name': 449, 'cruel': 450, 'sound': 451, 'spancil': 452, 'county': 453, 'lies': 454, 'color': 455, 'thing': 456, 'decay': 457, 'sleep': 458, 'hours': 459, 'loving': 460, 'weary': 461, 'ringing': 462, 'please': 463, 'forget': 464, 'lie': 465, 'ran': 466, 'tore': 467, 'country': 468, 'fear': 469, 'fortune': 470, 'kissed': 471, 'alone': 472, 'ould': 473, 'cry': 474, 'dreams': 475, 'used': 476, 'horse': 477, 'break': 478, 'bells': 479, 'didnt': 480, 'weeks': 481, 'without': 482, 'raw': 483, 'nor': 484, 'twenty': 485, 'tune': 486, 'hed': 487, 'roving': 488, 'leaves': 489, 'cant': 490, 'death': 491, 'ten': 492, 'prison': 493, 'judge': 494, 'against': 495, 'lads': 496, 'shell': 497, 'fill': 498, 'valleys': 499, 'other': 500, 'pale': 501, 'joy': 502, 'wide': 503, 'bring': 504, 'ah': 505, 'cliffs': 506, 'city': 507, 'end': 508, 'turn': 509, 'sky': 510, 'born': 511, 'knew': 512, 'smiled': 513, 'rosie': 514, 'comes': 515, 'sayin': 516, 'lord': 517, 'dungannon': 518, 'blood': 519, 'air': 520, 'danny': 521, 'calling': 522, 'sunshine': 523, 'spring': 524, 'bid': 525, 'grow': 526, 'truth': 527, 'tear': 528, 'rings': 529, 'guns': 530, 'bay': 531, 'oflynn': 532, 'och': 533, 'stick': 534, 'rest': 535, 'four': 536, 'jewel': 537, 'tried': 538, 'grief': 539, 'answer': 540, 'kathleen': 541, 'fond': 542, 'eye': 543, 'goin': 544, 'pistols': 545, 'musha': 546, 'whack': 547, 'creole': 548, 'together': 549, 'room': 550, 'fall': 551, 'swore': 552, 'being': 553, 'step': 554, 'lark': 555, 'cailín': 556, 'deas': 557, 'crúite': 558, 'na': 559, 'mbó': 560, 'sir': 561, 'isle': 562, 'waiting': 563, 'magic': 564, 'skibbereen': 565, 'loud': 566, 'raise': 567, 'bent': 568, 'aged': 569, 'summer': 570, 'jenny': 571, 'excise': 572, 'rigadoo': 573, 'auld': 574, 'hearts': 575, 'nay': 576, 'stool': 577, 'farrell': 578, 'garden': 579, 'precious': 580, 'child': 581, 'slumber': 582, 'sleeping': 583, 'watch': 584, 'gently': 585, 'minstrel': 586, 'praise': 587, 'bell': 588, 'shaken': 589, 'immortal': 590, 'pray': 591, 'stay': 592, 'spoke': 593, 'cross': 594, 'brothers': 595, 'much': 596, 'past': 597, 'killarney': 598, 'sang': 599, 'tones': 600, 'ral': 601, 'wander': 602, 'cot': 603, 'feel': 604, 'yore': 605, 'answered': 606, 'divil': 607, 'middle': 608, 'bit': 609, 'led': 610, 'soldiers': 611, 'lily': 612, 'bed': 613, 'lassie': 614, 'clothes': 615, 'return': 616, 'broken': 617, 'derry': 618, 'sighed': 619, 'english': 620, 'tomorrow': 621, 'souls': 622, 'van': 623, 'diemans': 624, 'law': 625, 'neither': 626, 'winds': 627, 'rather': 628, 'doesnt': 629, 'rosy': 630, 'neatest': 631, 'hands': 632, 'whereon': 633, 'stands': 634, 'write': 635, 'thousand': 636, 'fare': 637, 'youd': 638, 'velvet': 639, 'neat': 640, 'landed': 641, 'health': 642, 'kellswater': 643, 'quiet': 644, 'stars': 645, 'beside': 646, 'warm': 647, 'sunday': 648, 'grey': 649, 'ocean': 650, 'sad': 651, 'spend': 652, 'kilkenny': 653, 'silver': 654, 'view': 655, 'west': 656, 'plain': 657, 'barrow': 658, 'broad': 659, 'narrow': 660, 'crying': 661, 'wonder': 662, 'save': 663, 'stop': 664, 'tender': 665, 'told': 666, 'lip': 667, 'dance': 668, 'foot': 669, 'kilrain': 670, 'saint': 671, 'visit': 672, 'mossy': 673, 'wexford': 674, 'irishmen': 675, 'shadow': 676, 'tho': 677, 'salley': 678, 'gardens': 679, 'foolish': 680, 'youth': 681, 'fade': 682, 'war': 683, 'believe': 684, 'which': 685, 'change': 686, 'entwine': 687, 'turns': 688, 'turned': 689, 'crown': 690, 'played': 691, 'captain': 692, 'blow': 693, 'children': 694, 'slainte': 695, 'gentle': 696, 'heavens': 697, 'bloom': 698, 'grand': 699, 'bush': 700, 'nest': 701, 'rich': 702, 'parting': 703, 'better': 704, 'window': 705, 'haste': 706, 'fresh': 707, 'stream': 708, 'rays': 709, 'ma': 710, 'ring': 711, 'lad': 712, 'athy': 713, 'drop': 714, 'hardly': 715, 'done': 716, 'arm': 717, 'leg': 718, 'beg': 719, 'drew': 720, 'bold': 721, 'drawn': 722, 'jail': 723, 'writin': 724, 'farewell': 725, 'tired': 726, 'lake': 727, 'want': 728, 'ringlets': 729, 'myself': 730, 'songs': 731, 'reel': 732, 'steps': 733, 'hearty': 734, 'fainted': 735, 'called': 736, 'under': 737, 'toe': 738, 'mairi': 739, 'fairest': 740, 'darlin': 741, 'bird': 742, 'memory': 743, 'lips': 744, 'sweetly': 745, 'morrow': 746, 'consent': 747, 'else': 748, 'sold': 749, 'stout': 750, 'pair': 751, 'drinking': 752, 'meself': 753, 'fray': 754, 'pike': 755, 'coat': 756, 'beneath': 757, 'rent': 758, 'part': 759, 'half': 760, 'head': 761, 'friend': 762, 'standing': 763, 'floor': 764, 'bare': 765, 'wed': 766, 'son': 767, 'pride': 768, 'vision': 769, 'sword': 770, 'after': 771, 'won': 772, 'farmers': 773, 'flower': 774, 'nut': 775, 'surely': 776, 'stood': 777, 'wandered': 778, 'athenry': 779, 'rising': 780, 'beating': 781, 'form': 782, 'dhu': 783, 'buy': 784, 'laughter': 785, 'wear': 786, 'raking': 787, 'rakes': 788, 'claret': 789, 'shure': 790, 'tralee': 791, 'slower': 792, 'lower': 793, 'deep': 794, 'wearin': 795, 'duram': 796, 'takes': 797, 'beware': 798, 'steal': 799, 'brings': 800, 'things': 801, 'joys': 802, 'bunch': 803, 'sailor': 804, 'chanced': 805, 'pass': 806, 'angels': 807, 'send': 808, 'drowsy': 809, 'keeping': 810, 'spirit': 811, 'stealing': 812, 'feeling': 813, 'roam': 814, 'presence': 815, 'heavenward': 816, 'dust': 817, 'dim': 818, 'journey': 819, 'waves': 820, 'frightened': 821, 'leaving': 822, 'struggle': 823, 'parents': 824, 'courage': 825, 'weeping': 826, 'pain': 827, 'mist': 828, 'felt': 829, 'roared': 830, 'making': 831, 'fever': 832, 'moment': 833, 'distance': 834, 'wailing': 835, 'oft': 836, 'held': 837, 'fast': 838, 'cabin': 839, 'honey': 840, 'diddle': 841, 'clearly': 842, 'open': 843, 'opened': 844, 'table': 845, 'wine': 846, 'lay': 847, 'shells': 848, 'sailed': 849, 'drown': 850, 'fetters': 851, 'chains': 852, 'wives': 853, 'sorrow': 854, 'thoughts': 855, 'cursed': 856, 'hell': 857, 'five': 858, 'buried': 859, 'lost': 860, 'endless': 861, 'slavery': 862, 'gun': 863, 'rain': 864, 'cares': 865, 'ghosts': 866, 'runaway': 867, 'twill': 868, 'month': 869, 'meadows': 870, 'prettiest': 871, 'winters': 872, 'satisfied': 873, 'few': 874, 'short': 875, 'lines': 876, 'shone': 877, 'shoulder': 878, 'belfast': 879, 'trade': 880, 'bad': 881, 'caused': 882, 'stray': 883, 'meaning': 884, 'damsel': 885, 'appear': 886, 'seven': 887, 'sentence': 888, 'jolly': 889, 'whenever': 890, 'wee': 891, 'wife': 892, 'lives': 893, 'martha': 894, 'courted': 895, 'bridgit': 896, 'omalley': 897, 'desolation': 898, 'thorn': 899, 'gaze': 900, 'stone': 901, 'approaching': 902, 'sets': 903, 'carrigfergus': 904, 'nights': 905, 'swim': 906, 'wings': 907, 'sober': 908, 'travel': 909, 'native': 910, 'places': 911, 'slopes': 912, 'hares': 913, 'lofty': 914, 'malone': 915, 'wheeled': 916, 'streets': 917, 'enough': 918, 'reilly': 919, 'tough': 920, 'whispers': 921, 'phil': 922, 'threw': 923, 'straight': 924, 'belles': 925, 'moor': 926, 'brand': 927, 'shapes': 928, 'work': 929, 'vow': 930, 'blarney': 931, 'paid': 932, 'bower': 933, 'remain': 934, 'charming': 935, 'storied': 936, 'chieftains': 937, 'slaughter': 938, 'bann': 939, 'boyne': 940, 'liffey': 941, 'gallant': 942, 'awake': 943, 'greet': 944, 'meadow': 945, 'sweeter': 946, 'dirty': 947, 'cats': 948, 'crossed': 949, 'field': 950, 'river': 951, 'full': 952, 'aroon': 953, 'sends': 954, 'woe': 955, 'chain': 956, 'main': 957, 'charms': 958, 'fondly': 959, 'fleet': 960, 'fairy': 961, 'thine': 962, 'known': 963, 'truly': 964, 'close': 965, 'story': 966, 'flag': 967, 'sweetest': 968, 'honor': 969, 'playing': 970, 'mauser': 971, 'music': 972, 'tom': 973, 'hurrah': 974, 'big': 975, 'lead': 976, 'south': 977, 'generation': 978, 'freedom': 979, 'agin': 980, 'creature': 981, 'dad': 982, 'venture': 983, 'word': 984, 'wonderful': 985, 'crazy': 986, 'lazy': 987, 'grave': 988, 'jest': 989, 'remark': 990, 'strangers': 991, 'strong': 992, 'shook': 993, 'walk': 994, 'north': 995, 'ours': 996, 'cease': 997, 'strife': 998, 'whats': 999, 'lilacs': 1000, 'prove': 1001, 'sweetheart': 1002, 'letters': 1003, 'sent': 1004, 'speak': 1005, 'brow': 1006, 'albert': 1007, 'mooney': 1008, 'fighting': 1009, 'fingers': 1010, 'toes': 1011, 'john': 1012, 'hurroo': 1013, 'drums': 1014, 'beguiled': 1015, 'carry': 1016, 'bone': 1017, 'havent': 1018, 'walkin': 1019, 'kilgary': 1020, 'pepper': 1021, 'countin': 1022, 'forth': 1023, 'deliver': 1024, 'daddy': 1025, 'em': 1026, 'deceive': 1027, 'between': 1028, 'even': 1029, 'prisoner': 1030, 'fists': 1031, 'knocked': 1032, 'carriages': 1033, 'rollin': 1034, 'juice': 1035, 'courtin': 1036, 'ponchartrain': 1037, 'does': 1038, 'stranger': 1039, 'marry': 1040, 'adieu': 1041, 'ask': 1042, 'tipped': 1043, 'arrived': 1044, 'ladies': 1045, 'potatoes': 1046, 'courting': 1047, 'miss': 1048, 'small': 1049, 'ned': 1050, 'ribbons': 1051, 'heel': 1052, 'bonny': 1053, 'pipe': 1054, 'thrush': 1055, 'sweethearts': 1056, 'unto': 1057, 'rise': 1058, 'softly': 1059, 'milking': 1060, 'rare': 1061, 'pity': 1062, 'treasure': 1063, 'noon': 1064, 'sailing': 1065, 'banish': 1066, 'riches': 1067, 'comfort': 1068, 'yonder': 1069, 'flows': 1070, 'fairer': 1071, 'lass': 1072, 'woods': 1073, 'strayed': 1074, 'locks': 1075, 'breaking': 1076, 'june': 1077, 'started': 1078, 'hearted': 1079, 'beer': 1080, 'daylight': 1081, 'among': 1082, 'bundle': 1083, 'connaught': 1084, 'quay': 1085, 'erins': 1086, 'galway': 1087, 'fearless': 1088, 'bravely': 1089, 'marches': 1090, 'fate': 1091, 'neck': 1092, 'trod': 1093, 'marched': 1094, 'antrim': 1095, 'sash': 1096, 'flashed': 1097, 'hath': 1098, 'foemans': 1099, 'fight': 1100, 'heavy': 1101, 'bore': 1102, 'mans': 1103, 'counter': 1104, 'dozen': 1105, 'gallon': 1106, 'bottles': 1107, 'diamond': 1108, 'resemble': 1109, 'tiny': 1110, 'friendly': 1111, 'weather': 1112, 'inside': 1113, 'remember': 1114, 'someone': 1115, 'hat': 1116, 'body': 1117, 'dancers': 1118, 'hanging': 1119, 'empty': 1120, 'shoes': 1121, 'broke': 1122, 'december': 1123, 'move': 1124, 'reason': 1125, 'roof': 1126, 'naught': 1127, 'tower': 1128, 'power': 1129, 'king': 1130, 'dreaming': 1131, 'crew': 1132, 'whos': 1133, 'mccann': 1134, 'smoke': 1135, 'notes': 1136, 'yeoman': 1137, 'cavalry': 1138, 'guard': 1139, 'forced': 1140, 'brother': 1141, 'cousin': 1142, 'blame': 1143, 'croppy': 1144, 'dressed': 1145, 'trees': 1146, 'wore': 1147, 'words': 1148, 'swiftly': 1149, 'dawn': 1150, 'lovd': 1151, 'voices': 1152, 'moaning': 1153, 'dark': 1154, 'gather': 1155, 'tay': 1156, 'swinging': 1157, 'drinkin': 1158, 'sitting': 1159, 'stile': 1160, 'springing': 1161, 'yours': 1162, 'kept': 1163, 'aisey': 1164, 'rub': 1165, 'dub': 1166, 'dow': 1167, 'shelah': 1168, 'fairly': 1169, 'beggarman': 1170, 'begging': 1171, 'slept': 1172, 'holes': 1173, 'coming': 1174, 'thru': 1175, 'boo': 1176, 'lady': 1177, 'kerry': 1178, 'pipers': 1179, 'laugh': 1180, 'beaming': 1181, 'guineas': 1182, 'least': 1183, 'diggin': 1184, 'mourne': 1185, 'spending': 1186, 'mellow': 1187, 'plying': 1188, 'slowly': 1189, 'mooncoin': 1190, 'flow': 1191, 'sounds': 1192, 'shine': 1193, 'cool': 1194, 'crystal': 1195, 'fountain': 1196, 'moonlight': 1197, 'grandmother': 1198, 'crooning': 1199, 'merrily': 1200, 'spins': 1201, 'lightly': 1202, 'moving': 1203, 'lattice': 1204, 'grove': 1205, 'swings': 1206, 'finger': 1207, 'shamrock': 1208, 'pocket': 1209, 'springtime': 1210, 'gilgarra': 1211, 'rapier': 1212, 'ringum': 1213, 'mornin': 1214, 'heather': 1215, 'build': 1216, 'maidens': 1217, 'prime': 1218, 'nlyme': 1219, 'flavours': 1220, 'lusty': 1221, 'reminded': 1222, 'attend': 1223, 'guardian': 1224, 'creeping': 1225, 'dale': 1226, 'vigil': 1227, 'visions': 1228, 'revealing': 1229, 'breathes': 1230, 'holy': 1231, 'strains': 1232, 'hover': 1233, 'hark': 1234, 'solemn': 1235, 'winging': 1236, 'earthly': 1237, 'shalt': 1238, 'awaken': 1239, 'destiny': 1240, 'emigrants': 1241, 'amid': 1242, 'longing': 1243, 'parted': 1244, 'townland': 1245, 'vessel': 1246, 'crowded': 1247, 'disquieted': 1248, 'folk': 1249, 'escape': 1250, 'hardship': 1251, 'sustaining': 1252, 'glimpse': 1253, 'faded': 1254, 'strangely': 1255, 'seas': 1256, 'anger': 1257, 'desperate': 1258, 'plight': 1259, 'worsened': 1260, 'delirium': 1261, 'possessed': 1262, 'clouded': 1263, 'prayers': 1264, 'begged': 1265, 'forgiveness': 1266, 'seeking': 1267, 'distant': 1268, 'mither': 1269, 'simple': 1270, 'ditty': 1271, 'ld': 1272, 'li': 1273, 'hush': 1274, 'lullaby': 1275, 'huggin': 1276, 'hummin': 1277, 'rock': 1278, 'asleep': 1279, 'outside': 1280, 'modestly': 1281, 'ry': 1282, 'ay': 1283, 'di': 1284, 're': 1285, 'dai': 1286, 'rie': 1287, 'shc': 1288, 'bridle': 1289, 'stable': 1290, 'oats': 1291, 'eat': 1292, 'soldier': 1293, 'aisy': 1294, 'arose': 1295, 'christmas': 1296, '1803': 1297, 'australia': 1298, 'marks': 1299, 'carried': 1300, 'rusty': 1301, 'iron': 1302, 'wains': 1303, 'mainsails': 1304, 'unfurled': 1305, 'curses': 1306, 'hurled': 1307, 'swell': 1308, 'moth': 1309, 'firelights': 1310, 'horses': 1311, 'rode': 1312, 'taking': 1313, 'hades': 1314, 'twilight': 1315, 'forty': 1316, 'slime': 1317, 'climate': 1318, 'bravery': 1319, 'ended': 1320, 'bond': 1321, 'rebel': 1322, 'iii': 1323, 'violin': 1324, 'clay': 1325, 'sooner': 1326, 'sport': 1327, 'colour': 1328, 'knows': 1329, 'earth': 1330, 'serve': 1331, 'clyde': 1332, 'mourn': 1333, 'weep': 1334, 'suffer': 1335, 'diamonds': 1336, 'queen': 1337, 'hung': 1338, 'tied': 1339, 'apprenticed': 1340, 'happiness': 1341, 'misfortune': 1342, 'follow': 1343, 'strolling': 1344, 'selling': 1345, 'bar': 1346, 'customer': 1347, 'slipped': 1348, 'luck': 1349, 'jury': 1350, 'trial': 1351, 'case': 1352, 'warning': 1353, 'liquor': 1354, 'porter': 1355, 'pleasures': 1356, 'fishing': 1357, 'farming': 1358, 'glens': 1359, 'softest': 1360, 'dripping': 1361, 'snare': 1362, 'lose': 1363, 'court': 1364, 'primrose': 1365, 'bee': 1366, 'hopeless': 1367, 'wonders': 1368, 'admiration': 1369, 'haunt': 1370, 'wherever': 1371, 'sands': 1372, 'purer': 1373, 'within': 1374, 'grieve': 1375, 'drumslieve': 1376, 'ballygrant': 1377, 'deepest': 1378, 'boatsman': 1379, 'ferry': 1380, 'childhood': 1381, 'reflections': 1382, 'boyhood': 1383, 'melting': 1384, 'roaming': 1385, 'reported': 1386, 'marble': 1387, 'stones': 1388, 'ink': 1389, 'support': 1390, 'drunk': 1391, 'seldom': 1392, 'sick': 1393, 'numbered': 1394, 'foam': 1395, 'compare': 1396, 'sights': 1397, 'coast': 1398, 'clare': 1399, 'kilkee': 1400, 'kilrush': 1401, 'watching': 1402, 'pheasants': 1403, 'homes': 1404, 'streams': 1405, 'dublins': 1406, 'cockles': 1407, 'mussels': 1408, 'fish': 1409, 'monger': 1410, 'ghost': 1411, 'wheels': 1412, 'eden': 1413, 'vanished': 1414, 'finea': 1415, 'halfway': 1416, 'cootehill': 1417, 'gruff': 1418, 'whispering': 1419, 'crow': 1420, 'newborn': 1421, 'babies': 1422, 'huff': 1423, 'start': 1424, 'sorrowful': 1425, 'squall': 1426, 'babys': 1427, 'toil': 1428, 'worn': 1429, 'fore': 1430, 'flute': 1431, 'yer': 1432, 'boot': 1433, 'magee': 1434, 'scruff': 1435, 'slanderin': 1436, 'marchin': 1437, 'assisted': 1438, 'drain': 1439, 'dudeen': 1440, 'puff': 1441, 'whisperings': 1442, 'barrin': 1443, 'chocolate': 1444, 'feegee': 1445, 'sort': 1446, 'moonshiny': 1447, 'stuff': 1448, 'addle': 1449, 'brain': 1450, 'ringin': 1451, 'glamour': 1452, 'gas': 1453, 'guff': 1454, 'whisper': 1455, 'oil': 1456, 'remarkable': 1457, 'policeman': 1458, 'bluff': 1459, 'maintain': 1460, 'guril': 1461, 'sic': 1462, 'passage': 1463, 'rough': 1464, 'borne': 1465, 'breeze': 1466, 'boundless': 1467, 'stupendous': 1468, 'roll': 1469, 'thundering': 1470, 'motion': 1471, 'mermaids': 1472, 'fierce': 1473, 'tempest': 1474, 'gathers': 1475, 'oneill': 1476, 'odonnell': 1477, 'lucan': 1478, 'oconnell': 1479, 'brian': 1480, 'drove': 1481, 'danes': 1482, 'patrick': 1483, 'vermin': 1484, 'whose': 1485, 'benburb': 1486, 'blackwater': 1487, 'owen': 1488, 'roe': 1489, 'munroe': 1490, 'lambs': 1491, 'skip': 1492, 'views': 1493, 'enchanting': 1494, 'rostrevor': 1495, 'groves': 1496, 'lakes': 1497, 'ride': 1498, 'tide': 1499, 'majestic': 1500, 'shannon': 1501, 'sail': 1502, 'loch': 1503, 'neagh': 1504, 'ross': 1505, 'gorey': 1506, 'saxon': 1507, 'tory': 1508, 'soil': 1509, 'sanctified': 1510, 'enemies': 1511, 'links': 1512, 'encumbered': 1513, 'resound': 1514, 'hosannahs': 1515, 'bide': 1516, 'hushed': 1517, 'lying': 1518, 'kneel': 1519, 'ave': 1520, 'tread': 1521, 'fail': 1522, 'simply': 1523, 'gasworks': 1524, 'croft': 1525, 'dreamed': 1526, 'canal': 1527, 'factory': 1528, 'clouds': 1529, 'drifting': 1530, 'prowling': 1531, 'beat': 1532, 'springs': 1533, 'siren': 1534, 'docks': 1535, 'train': 1536, 'smelled': 1537, 'smokey': 1538, 'sharp': 1539, 'axe': 1540, 'steel': 1541, 'tempered': 1542, 'chop': 1543, 't': 1544, 'agree': 1545, 'leaning': 1546, 'weirs': 1547, 'ray': 1548, 'glow': 1549, 'changeless': 1550, 'constant': 1551, 'bounding': 1552, 'castles': 1553, 'sacked': 1554, 'scattered': 1555, 'fixed': 1556, 'endearing': 1557, 'gifts': 1558, 'fading': 1559, 'wouldst': 1560, 'adored': 1561, 'loveliness': 1562, 'ruin': 1563, 'itself': 1564, 'verdantly': 1565, 'unprofaned': 1566, 'fervor': 1567, 'faith': 1568, 'forgets': 1569, 'sunflower': 1570, 'rag': 1571, 'games': 1572, 'hold': 1573, 'defend': 1574, 'veteran': 1575, 'volunteers': 1576, 'pat': 1577, 'pearse': 1578, 'clark': 1579, 'macdonagh': 1580, 'macdiarmada': 1581, 'mcbryde': 1582, 'james': 1583, 'connolly': 1584, 'placed': 1585, 'machine': 1586, 'ranting': 1587, 'hour': 1588, 'bullet': 1589, 'stuck': 1590, 'craw': 1591, 'poisoning': 1592, 'ceannt': 1593, 'lions': 1594, 'union': 1595, 'poured': 1596, 'dismay': 1597, 'horror': 1598, 'englishmen': 1599, 'khaki': 1600, 'renown': 1601, 'fame': 1602, 'forefathers': 1603, 'blaze': 1604, 'priests': 1605, 'offer': 1606, 'charmin': 1607, 'variety': 1608, 'renownd': 1609, 'learnin': 1610, 'piety': 1611, 'advance': 1612, 'widout': 1613, 'impropriety': 1614, 'flowr': 1615, 'cho': 1616, 'powrfulest': 1617, 'preacher': 1618, 'tenderest': 1619, 'teacher': 1620, 'kindliest': 1621, 'donegal': 1622, 'talk': 1623, 'provost': 1624, 'trinity': 1625, 'famous': 1626, 'greek': 1627, 'latinity': 1628, 'divils': 1629, 'divinity': 1630, 'd': 1631, 'likes': 1632, 'logic': 1633, 'mythology': 1634, 'thayology': 1635, 'conchology': 1636, 'sinners': 1637, 'wishful': 1638, 'childer': 1639, 'avick': 1640, 'gad': 1641, 'flock': 1642, 'grandest': 1643, 'control': 1644, 'checking': 1645, 'coaxin': 1646, 'onaisy': 1647, 'lifting': 1648, 'avoidin': 1649, 'frivolity': 1650, 'seasons': 1651, 'innocent': 1652, 'jollity': 1653, 'playboy': 1654, 'claim': 1655, 'equality': 1656, 'comicality': 1657, 'bishop': 1658, 'lave': 1659, 'gaiety': 1660, 'laity': 1661, 'clergy': 1662, 'jewels': 1663, 'plundering': 1664, 'pillage': 1665, 'starved': 1666, 'cries': 1667, 'thems': 1668, 'bondage': 1669, 'fourth': 1670, 'tabhair': 1671, 'dom': 1672, 'lámh': 1673, 'harmony': 1674, 'east': 1675, 'destroy': 1676, 'command': 1677, 'gesture': 1678, 'troubles': 1679, 'weak': 1680, 'peoples': 1681, 'creeds': 1682, 'lets': 1683, 'needs': 1684, 'passion': 1685, 'fashion': 1686, 'guide': 1687, 'share': 1688, 'sparkling': 1689, 'meeting': 1690, 'iull': 1691, 'contented': 1692, 'ache': 1693, 'painful': 1694, 'wrote': 1695, 'twisted': 1696, 'twined': 1697, 'cheek': 1698, 'bedim': 1699, 'holds': 1700, 'smiles': 1701, 'scarcely': 1702, 'darkning': 1703, 'beyond': 1704, 'yearn': 1705, 'laughs': 1706, 'humble': 1707, 'brightest': 1708, 'gleam': 1709, 'forgot': 1710, 'pulled': 1711, 'comb': 1712, 'counting': 1713, 'knock': 1714, 'murray': 1715, 'fellow': 1716, 'hail': 1717, 'tumblin': 1718, 'apple': 1719, 'pie': 1720, 'gets': 1721, 'doleful': 1722, 'enemy': 1723, 'nearly': 1724, 'slew': 1725, 'queer': 1726, 'mild': 1727, 'legs': 1728, 'indeed': 1729, 'island': 1730, 'sulloon': 1731, 'flesh': 1732, 'yere': 1733, 'armless': 1734, 'boneless': 1735, 'chickenless': 1736, 'egg': 1737, 'yell': 1738, 'bowl': 1739, 'rolling': 1740, 'swearing': 1741, 'rattled': 1742, 'saber': 1743, 'deceiver': 1744, 'rig': 1745, 'um': 1746, 'du': 1747, 'rum': 1748, 'jar': 1749, 'shinin': 1750, 'coins': 1751, 'promised': 1752, 'vowed': 1753, 'devils': 1754, 'awakened': 1755, 'six': 1756, 'guards': 1757, 'numbers': 1758, 'odd': 1759, 'flew': 1760, 'mistaken': 1761, 'mollys': 1762, 'robbing': 1763, 'sentry': 1764, 'sligo': 1765, 'fishin': 1766, 'bowlin': 1767, 'others': 1768, 'railroad': 1769, 'ties': 1770, 'crossings': 1771, 'swamps': 1772, 'elevations': 1773, 'resolved': 1774, 'sunset': 1775, 'higher': 1776, 'win': 1777, 'allegators': 1778, 'wood': 1779, 'treated': 1780, 'shoulders': 1781, 'paint': 1782, 'picture': 1783, 'vain': 1784, 'returned': 1785, 'cottage': 1786, 'sociable': 1787, 'foaming': 1788, 'n': 1789, 'jeremy': 1790, 'lanigan': 1791, 'battered': 1792, 'hadnt': 1793, 'pound': 1794, 'farm': 1795, 'acres': 1796, 'party': 1797, 'listen': 1798, 'glisten': 1799, 'rows': 1800, 'ructions': 1801, 'invitation': 1802, 'minute': 1803, 'bees': 1804, 'cask': 1805, 'judy': 1806, 'odaly': 1807, 'milliner': 1808, 'wink': 1809, 'peggy': 1810, 'mcgilligan': 1811, 'lashings': 1812, 'punch': 1813, 'cakes': 1814, 'bacon': 1815, 'tea': 1816, 'nolans': 1817, 'dolans': 1818, 'ogradys': 1819, 'sounded': 1820, 'taras': 1821, 'hall': 1822, 'nelly': 1823, 'gray': 1824, 'rat': 1825, 'catchers': 1826, 'doing': 1827, 'kinds': 1828, 'nonsensical': 1829, 'polkas': 1830, 'whirligig': 1831, 'julia': 1832, 'banished': 1833, 'nonsense': 1834, 'twist': 1835, 'jig': 1836, 'mavrone': 1837, 'mad': 1838, 'ceiling': 1839, 'brooks': 1840, 'academy': 1841, 'learning': 1842, 'learn': 1843, 'couples': 1844, 'groups': 1845, 'accident': 1846, 'happened': 1847, 'terrance': 1848, 'mccarthy': 1849, 'finnertys': 1850, 'hoops': 1851, 'cried': 1852, 'meelia': 1853, 'murther': 1854, 'gathered': 1855, 'carmody': 1856, 'further': 1857, 'satisfaction': 1858, 'midst': 1859, 'kerrigan': 1860, 'declared': 1861, 'painted': 1862, 'suppose': 1863, 'morgan': 1864, 'powerful': 1865, 'stretched': 1866, 'smashed': 1867, 'chaneys': 1868, 'runctions': 1869, 'lick': 1870, 'phelim': 1871, 'mchugh': 1872, 'replied': 1873, 'introduction': 1874, 'kicked': 1875, 'terrible': 1876, 'hullabaloo': 1877, 'piper': 1878, 'strangled': 1879, 'squeezed': 1880, 'bellows': 1881, 'chanters': 1882, 'entangled': 1883, 'gaily': 1884, 'mairis': 1885, 'hillways': 1886, 'myrtle': 1887, 'bracken': 1888, 'sheilings': 1889, 'sake': 1890, 'rowans': 1891, 'herring': 1892, 'meal': 1893, 'peat': 1894, 'creel': 1895, 'bairns': 1896, 'weel': 1897, 'toast': 1898, 'soar': 1899, 'blackbird': 1900, 'note': 1901, 'linnet': 1902, 'lure': 1903, 'cozy': 1904, 'catch': 1905, 'company': 1906, 'harm': 1907, 'wit': 1908, 'recall': 1909, 'leisure': 1910, 'awhile': 1911, 'sorely': 1912, 'ruby': 1913, 'enthralled': 1914, 'sorry': 1915, 'theyd': 1916, 'falls': 1917, 'lot': 1918, 'tuned': 1919, 'bough': 1920, 'cow': 1921, 'chanting': 1922, 'melodious': 1923, 'scarce': 1924, 'soothed': 1925, 'solace': 1926, 'courtesy': 1927, 'salute': 1928, 'amiable': 1929, 'captive': 1930, 'slave': 1931, 'future': 1932, 'banter': 1933, 'enamour': 1934, 'indies': 1935, 'afford': 1936, 'transparently': 1937, 'flame': 1938, 'add': 1939, 'fuel': 1940, 'grant': 1941, 'desire': 1942, 'expire': 1943, 'wealth': 1944, 'damer': 1945, 'african': 1946, 'devonshire': 1947, 'lamp': 1948, 'alladin': 1949, 'genie': 1950, 'also': 1951, 'withdraw': 1952, 'tease': 1953, 'single': 1954, 'airy': 1955, 'embarrass': 1956, 'besides': 1957, 'almanack': 1958, 'useless': 1959, 'date': 1960, 'ware': 1961, 'rate': 1962, 'fragrance': 1963, 'loses': 1964, 'consumed': 1965, 'october': 1966, 'knowing': 1967, 'steer': 1968, 'blast': 1969, 'danger': 1970, 'farthing': 1971, 'affection': 1972, 'enjoy': 1973, 'choose': 1974, 'killarneys': 1975, 'sister': 1976, 'pains': 1977, 'loss': 1978, 'tuam': 1979, 'saluted': 1980, 'drank': 1981, 'pint': 1982, 'smother': 1983, 'reap': 1984, 'cut': 1985, 'goblins': 1986, 'bought': 1987, 'brogues': 1988, 'rattling': 1989, 'bogs': 1990, 'frightning': 1991, 'dogs': 1992, 'hunt': 1993, 'hare': 1994, 'follol': 1995, 'rah': 1996, 'mullingar': 1997, 'rested': 1998, 'limbs': 1999, 'blithe': 2000, 'heartfrom': 2001, 'paddys': 2002, 'cure': 2003, 'lassies': 2004, 'laughing': 2005, 'curious': 2006, 'style': 2007, 'twould': 2008, 'bubblin': 2009, 'hired': 2010, 'wages': 2011, 'required': 2012, 'almost': 2013, 'deprived': 2014, 'stroll': 2015, 'quality': 2016, 'locality': 2017, 'something': 2018, 'wobblin': 2019, 'enquiring': 2020, 'rogue': 2021, 'brogue': 2022, 'wasnt': 2023, 'vogue': 2024, 'spirits': 2025, 'falling': 2026, 'jumped': 2027, 'aboard': 2028, 'pigs': 2029, 'rigs': 2030, 'jigs': 2031, 'bubbling': 2032, 'holyhead': 2033, 'wished': 2034, 'instead': 2035, 'bouys': 2036, 'liverpool': 2037, 'safely': 2038, 'fool': 2039, 'boil': 2040, 'temper': 2041, 'losing': 2042, 'abusing': 2043, 'shillelagh': 2044, 'nigh': 2045, 'hobble': 2046, 'load': 2047, 'hurray': 2048, 'joined': 2049, 'affray': 2050, 'quitely': 2051, 'cleared': 2052, 'host': 2053, 'march': 2054, 'faces': 2055, 'farmstead': 2056, 'fishers': 2057, 'ban': 2058, 'vengeance': 2059, 'hapless': 2060, 'about': 2061, 'hemp': 2062, 'rope': 2063, 'clung': 2064, 'grim': 2065, 'array': 2066, 'earnest': 2067, 'stalwart': 2068, 'stainless': 2069, 'banner': 2070, 'marching': 2071, 'torn': 2072, 'furious': 2073, 'odds': 2074, 'keen': 2075, 'toomebridge': 2076, 'treads': 2077, 'upwards': 2078, 'traveled': 2079, 'quarters': 2080, 'below': 2081, 'hogshead': 2082, 'stack': 2083, 'stagger': 2084, 'dig': 2085, 'hole': 2086, 'couple': 2087, 'scratch': 2088, 'consolation': 2089, 'tyrant': 2090, 'remorseless': 2091, 'foe': 2092, 'lift': 2093, 'stranded': 2094, 'prince': 2095, 'edward': 2096, 'coffee': 2097, 'trace': 2098, 'fiddlin': 2099, 'dime': 2100, 'shy': 2101, 'hello': 2102, 'wintry': 2103, 'yellow': 2104, 'somewhere': 2105, 'written': 2106, 'begin': 2107, 'tap': 2108, 'caught': 2109, 'leap': 2110, 'clumsy': 2111, 'graceful': 2112, 'fiddlers': 2113, 'everywhere': 2114, 'boots': 2115, 'laughtcr': 2116, 'suits': 2117, 'easter': 2118, 'gowns': 2119, 'sailors': 2120, 'pianos': 2121, 'setting': 2122, 'someones': 2123, 'hats': 2124, 'rack': 2125, 'chair': 2126, 'wooden': 2127, 'feels': 2128, 'touch': 2129, 'awaitin': 2130, 'thc': 2131, 'fiddles': 2132, 'closet': 2133, 'strings': 2134, 'tbe': 2135, 'covers': 2136, 'buttoned': 2137, 'sometimes': 2138, 'melody': 2139, 'passes': 2140, 'slight': 2141, 'lack': 2142, 'moved': 2143, 'homeward': 2144, 'swan': 2145, 'moves': 2146, 'goods': 2147, 'gear': 2148, 'din': 2149, 'rude': 2150, 'wherein': 2151, 'dwell': 2152, 'abandon': 2153, 'energy': 2154, 'blight': 2155, 'praties': 2156, 'sheep': 2157, 'cattle': 2158, 'taxes': 2159, 'unpaid': 2160, 'redeem': 2161, 'bleak': 2162, 'landlord': 2163, 'sheriff': 2164, 'spleen': 2165, 'heaved': 2166, 'sigh': 2167, 'bade': 2168, 'goodbye': 2169, 'stony': 2170, 'anguish': 2171, 'seeing': 2172, 'feeble': 2173, 'frame': 2174, 'wrapped': 2175, 'c�ta': 2176, 'm�r': 2177, 'unseen': 2178, 'stern': 2179, 'rally': 2180, 'cheer': 2181, 'revenge': 2182, 'waking': 2183, 'wisdom': 2184, 'dwelling': 2185, 'battleshield': 2186, 'dignity': 2187, 'shelter': 2188, 'heed': 2189, 'inheritance': 2190, 'heavem': 2191, 'heaven': 2192, 'victory': 2193, 'reach': 2194, 'whatever': 2195, 'befall': 2196, 'ruler': 2197, 'pleasant': 2198, 'rambling': 2199, 'board': 2200, 'followed': 2201, 'shortly': 2202, 'anchor': 2203, '23rd': 2204, 'lrelands': 2205, 'daughters': 2206, 'crowds': 2207, 'assembled': 2208, 'fulfill': 2209, 'jovial': 2210, 'conversations': 2211, 'neighbors': 2212, 'turning': 2213, 'tailor': 2214, 'quigley': 2215, 'bould': 2216, 'britches': 2217, 'lived': 2218, 'flying': 2219, 'dove': 2220, 'hiii': 2221, 'dreamt': 2222, 'joking': 2223, 'manys': 2224, 'cock': 2225, 'shrill': 2226, 'awoke': 2227, 'california': 2228, 'miles': 2229, 'banbridge': 2230, 'july': 2231, 'boreen': 2232, 'sheen': 2233, 'coaxing': 2234, 'elf': 2235, 'shake': 2236, 'bantry': 2237, 'onward': 2238, 'sped': 2239, 'gazed': 2240, 'passerby': 2241, 'gem': 2242, 'irelands': 2243, 'travelled': 2244, 'hit': 2245, 'career': 2246, 'square': 2247, 'surrendered': 2248, 'tenant': 2249, 'shawl': 2250, 'gown': 2251, 'crossroads': 2252, 'dress': 2253, 'try': 2254, 'sheeps': 2255, 'deludhering': 2256, 'yoke': 2257, 'rust': 2258, 'plow': 2259, 'fireside': 2260, 'sits': 2261, 'whistle': 2262, 'changing': 2263, 'fright': 2264, 'downfall': 2265, 'cornwall': 2266, 'parlour': 2267, 'passing': 2268, 'william': 2269, 'betray': 2270, 'guinea': 2271, 'walking': 2272, 'mounted': 2273, 'platform': 2274, 'deny': 2275, 'walked': 2276, 'margin': 2277, 'lough': 2278, 'leane': 2279, 'bloomed': 2280, 'whom': 2281, 'cap': 2282, 'cloak': 2283, 'glossy': 2284, 'pail': 2285, 'palm': 2286, 'venus': 2287, 'bank': 2288, 'travelians': 2289, 'babes': 2290, 'freebirds': 2291, 'grew': 2292, 'matters': 2293, 'famine': 2294, 'rebelled': 2295, 'windswept': 2296, 'harbour': 2297, 'botany': 2298, 'whilst': 2299, 'wan': 2300, 'cloud': 2301, 'shannons': 2302, 'returnd': 2303, 'doubts': 2304, 'fears': 2305, 'aching': 2306, 'seemd': 2307, 'mingling': 2308, 'flood': 2309, 'path': 2310, 'wrath': 2311, 'lamenting': 2312, 'sudden': 2313, 'kissd': 2314, 'showrs': 2315, 'flowing': 2316, 'laughd': 2317, 'beam': 2318, 'soared': 2319, 'aloft': 2320, 'phantom': 2321, 'outspread': 2322, 'throbbing': 2323, 'hid': 2324, 'treasures': 2325, 'pots': 2326, 'tin': 2327, 'cans': 2328, 'mash': 2329, 'bran': 2330, 'barney': 2331, 'peeled': 2332, 'searching': 2333, 'connemara': 2334, 'butcher': 2335, 'quart': 2336, 'bottle': 2337, 'help': 2338, 'gate': 2339, 'glory': 2340, 'lane': 2341, 'village': 2342, 'church': 2343, 'spire': 2344, 'graveyard': 2345, 'baby': 2346, 'blessing': 2347, 'hoping': 2348, 'trust': 2349, 'strength': 2350, 'thank': 2351, 'bidding': 2352, 'bread': 2353, 'shines': 2354, 'fifty': 2355, 'often': 2356, 'shut': 2357, 'frisky': 2358, 'pig': 2359, 'whisky': 2360, 'uncle': 2361, 'enlisted': 2362, 'trudged': 2363, 'bosom': 2364, 'daisy': 2365, 'drubbing': 2366, 'shirts': 2367, 'battle': 2368, 'blows': 2369, 'pate': 2370, 'bothered': 2371, 'rarely': 2372, 'dropped': 2373, 'honest': 2374, 'thinks': 2375, 'eight': 2376, 'score': 2377, 'basin': 2378, 'zoo': 2379, 'everybody': 2380, 'calls': 2381, 'trades': 2382, 'dinner': 2383, 'slip': 2384, 'corner': 2385, 'barn': 2386, 'currabawn': 2387, 'shocking': 2388, 'wet': 2389, 'raindrops': 2390, 'rats': 2391, 'peek': 2392, 'waken': 2393, 'spotted': 2394, 'apron': 2395, 'calico': 2396, 'blouse': 2397, 'frighten': 2398, 'afraid': 2399, 'flaxen': 2400, 'haired': 2401, 'rags': 2402, 'tags': 2403, 'leggins': 2404, 'collar': 2405, 'tie': 2406, 'goggles': 2407, 'fashioned': 2408, 'bag': 2409, 'bulging': 2410, 'sack': 2411, 'peeping': 2412, 'skin': 2413, 'rink': 2414, 'doodle': 2415, 'getting': 2416, 'raked': 2417, 'gladness': 2418, 'tuning': 2419, 'fills': 2420, 'eily': 2421, 'prouder': 2422, 'thady': 2423, 'boldly': 2424, 'lasses': 2425, 'fled': 2426, 'silent': 2427, 'glad': 2428, 'echo': 2429, 'companions': 2430, 'soars': 2431, 'enchanted': 2432, 'granted': 2433, 'adoration': 2434, 'gives': 2435, 'joyous': 2436, 'elation': 2437, 'covered': 2438, 'winter': 2439, 'riding': 2440, 'cherry': 2441, 'coal': 2442, 'falter': 2443, 'bowed': 2444, 'bonnet': 2445, 'courteous': 2446, 'looks': 2447, 'engaging': 2448, 'sell': 2449, 'purse': 2450, 'yearly': 2451, 'need': 2452, 'market': 2453, 'gain': 2454, 'dearly': 2455, 'tarry': 2456, 'although': 2457, 'parlay': 2458, 'ranks': 2459, 'girded': 2460, 'slung': 2461, 'warrior': 2462, 'bard': 2463, 'betrays': 2464, 'rights': 2465, 'faithful': 2466, 'chords': 2467, 'asunder': 2468, 'sully': 2469, 'bravry': 2470, 'londons': 2471, 'sight': 2472, 'workin': 2473, 'sow': 2474, 'wheat': 2475, 'gangs': 2476, 'sweep': 2477, 'expressed': 2478, 'london': 2479, 'top': 2480, 'dresses': 2481, 'bath': 2482, 'startin': 2483, 'fashions': 2484, 'mccree': 2485, 'nature': 2486, 'designed': 2487, 'complexions': 2488, 'cream': 2489, 'regard': 2490, 'sip': 2491, 'colors': 2492, 'wait': 2493, 'waitin': 2494, 'sweeps': 2495, 'beauing': 2496, 'belling': 2497, 'windows': 2498, 'cursing': 2499, 'faster': 2500, 'waiters': 2501, 'bailiffs': 2502, 'duns': 2503, 'bacchus': 2504, 'begotten': 2505, 'politicians': 2506, 'funds': 2507, 'dadda': 2508, 'living': 2509, 'drives': 2510, 'having': 2511, 'racking': 2512, 'tenants': 2513, 'stewards': 2514, 'teasing': 2515, 'raising': 2516, 'wishing': 2517, 'sunny': 2518, 'doves': 2519, 'coo': 2520, 'neath': 2521, 'sunbeam': 2522, 'robin': 2523, 'waters': 2524, 'larks': 2525, 'join': 2526, 'breaks': 2527, 'oftimes': 2528, 'lilies': 2529, 'declining': 2530, 'vale': 2531, 'shades': 2532, 'mantle': 2533, 'spreading': 2534, 'listening': 2535, 'shedding': 2536, 'beginning': 2537, 'spinning': 2538, 'blind': 2539, 'drowsily': 2540, 'knitting': 2541, 'cheerily': 2542, 'noiselessly': 2543, 'whirring': 2544, 'foots': 2545, 'stirring': 2546, 'sprightly': 2547, 'chara': 2548, 'tapping': 2549, 'ivy': 2550, 'flapping': 2551, 'somebody': 2552, 'sighing': 2553, 'autumn': 2554, 'noise': 2555, 'chirping': 2556, 'holly': 2557, 'shoving': 2558, 'wrong': 2559, 'coolin': 2560, 'casement': 2561, 'rove': 2562, 'moons': 2563, 'brightly': 2564, 'shakes': 2565, 'lays': 2566, 'longs': 2567, 'lingers': 2568, 'glance': 2569, 'puts': 2570, 'lazily': 2571, 'easily': 2572, 'lowly': 2573, 'reels': 2574, 'noiseless': 2575, 'leaps': 2576, 'ere': 2577, 'lovers': 2578, 'roved': 2579, 'verdant': 2580, 'braes': 2581, 'skreen': 2582, 'countrie': 2583, 'foreign': 2584, 'strand': 2585, 'dewy': 2586, 'climb': 2587, 'rob': 2588, 'boat': 2589, 'sails': 2590, 'loaded': 2591, 'sink': 2592, 'leaned': 2593, 'oak': 2594, 'trusty': 2595, 'false': 2596, 'reached': 2597, 'pricked': 2598, 'waxes': 2599, 'fades': 2600, 'wholl': 2601, 'cockle': 2602, 'gloom': 2603, 'news': 2604, 'forbid': 2605, 'patricks': 2606, 'napper': 2607, 'tandy': 2608, 'hows': 2609, 'distressful': 2610, 'englands': 2611, 'remind': 2612, 'pull': 2613, 'throw': 2614, 'sod': 2615, 'root': 2616, 'underfoot': 2617, 'laws': 2618, 'blades': 2619, 'growin': 2620, 'dare': 2621, 'show': 2622, 'caubeen': 2623, 'year': 2624, 'returning': 2625, 'store': 2626, 'ale': 2627, 'frequent': 2628, 'landlady': 2629, 'credit': 2630, 'custom': 2631, 'sovereigns': 2632, 'landladys': 2633, 'wines': 2634, 'confess': 2635, 'pardon': 2636, 'prodigal': 2637, 'caress': 2638, 'forgive': 2639, 'ofttimes': 2640, 'wondering': 2641, 'powr': 2642, 'beguile': 2643, 'teardrop': 2644, 'lilting': 2645, 'laughters': 2646, 'twinkle': 2647, 'lilt': 2648, 'seems': 2649, 'linnets': 2650, 'real': 2651, 'regret': 2652, 'throughout': 2653, 'youths': 2654, 'chance': 2655, 'spied': 2656, 'receiver': 2657, 'counted': 2658, 'penny': 2659, 'bu': 2660, 'rungum': 2661, 'chamber': 2662, 'course': 2663, 'charges': 2664, 'filled': 2665, 'ready': 2666, 'footmen': 2667, 'likewise': 2668, 'draw': 2669, 'pistol': 2670, 'couldnt': 2671, 'shoot': 2672, 'robbin': 2673, 'jailer': 2674, 'tight': 2675, 'fisted': 2676, 'army': 2677, 'stationed': 2678, 'cork': 2679, 'roamin': 2680, 'swear': 2681, 'treat': 2682, 'sportin': 2683, 'hurley': 2684, 'bollin': 2685, 'maids': 2686, 'summertime': 2687, 'pluck': 2688, 'yon': 2689}\n","2690\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g4ajcxSYSbZG","colab_type":"code","colab":{}},"source":["input_sequences = []\n","for line in corpus:\n","\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n","\tfor i in range(1, len(token_list)):\n","\t\tn_gram_sequence = token_list[:i+1]\n","\t\tinput_sequences.append(n_gram_sequence)\n","\n","# pad sequences \n","max_sequence_len = max([len(x) for x in input_sequences])\n","input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n","\n","# create predictors and label\n","xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n","\n","ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GkGLgBYkP7dC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"82b0ca7a-8d56-4849-f817-49583c8d04dd","executionInfo":{"status":"ok","timestamp":1579213516774,"user_tz":480,"elapsed":991765,"user":{"displayName":"Hieu Quoc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBXboZp2dMx_so4JiaOdf8YR1jpP73S07Pde39vvw=s64","userId":"07041430737003441740"}}},"source":["model = Sequential()\n","# Hyper params: dim of embedded vector\n","model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n","model.add(Bidirectional(LSTM(150))) # Hyper param: 150 \n","# the dense has the same size as the one hot encoded: one neuron per word\n","model.add(Dense(total_words, activation='softmax'))\n","# adam is a pretty good optimizer for word generation\n","adam = Adam(lr=0.01)\n","model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n","# earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n","print(model.summary())\n","# We should train on a lot less epochs because the more complex the achitechtuer and the bigger the data is\n","# the fast it takes for this type of mode to converge as compare to before we had very little data\n","history = model.fit(xs, ys, epochs=100, verbose=1)\n","#print(model)\n","\n","# KEEP IN MIDN THE LAW OF DIMINISHING RETURN"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 15, 100)           269000    \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 300)               301200    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 2690)              809690    \n","=================================================================\n","Total params: 1,379,890\n","Trainable params: 1,379,890\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Train on 12038 samples\n","Epoch 1/100\n","12038/12038 [==============================] - 29s 2ms/sample - loss: 6.6791 - accuracy: 0.0703\n","Epoch 2/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 5.8085 - accuracy: 0.1117\n","Epoch 3/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 4.9302 - accuracy: 0.1612\n","Epoch 4/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 4.0047 - accuracy: 0.2291\n","Epoch 5/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 3.1490 - accuracy: 0.3334\n","Epoch 6/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 2.4491 - accuracy: 0.4486\n","Epoch 7/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 1.9587 - accuracy: 0.5431\n","Epoch 8/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 1.5573 - accuracy: 0.6322\n","Epoch 9/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 1.3117 - accuracy: 0.6838\n","Epoch 10/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 1.1450 - accuracy: 0.7234\n","Epoch 11/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 1.0515 - accuracy: 0.7481\n","Epoch 12/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.9950 - accuracy: 0.7590\n","Epoch 13/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 1.1400 - accuracy: 0.7189\n","Epoch 14/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 1.2331 - accuracy: 0.6872\n","Epoch 15/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 1.1483 - accuracy: 0.7053\n","Epoch 16/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.9983 - accuracy: 0.7426\n","Epoch 17/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.9170 - accuracy: 0.7669\n","Epoch 18/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8728 - accuracy: 0.7791\n","Epoch 19/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8722 - accuracy: 0.7756\n","Epoch 20/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.9275 - accuracy: 0.7613\n","Epoch 21/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 1.0337 - accuracy: 0.7276\n","Epoch 22/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 1.0023 - accuracy: 0.7391\n","Epoch 23/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 1.0091 - accuracy: 0.7382\n","Epoch 24/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.9723 - accuracy: 0.7476\n","Epoch 25/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.9371 - accuracy: 0.7547\n","Epoch 26/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8718 - accuracy: 0.7719\n","Epoch 27/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8491 - accuracy: 0.7785\n","Epoch 28/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8288 - accuracy: 0.7808\n","Epoch 29/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8529 - accuracy: 0.7776\n","Epoch 30/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.9591 - accuracy: 0.7508\n","Epoch 31/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 1.1004 - accuracy: 0.7129\n","Epoch 32/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 1.0802 - accuracy: 0.7181\n","Epoch 33/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 1.0207 - accuracy: 0.7318\n","Epoch 34/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8952 - accuracy: 0.7632\n","Epoch 35/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8356 - accuracy: 0.7800\n","Epoch 36/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7752 - accuracy: 0.7952\n","Epoch 37/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7491 - accuracy: 0.8056\n","Epoch 38/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7797 - accuracy: 0.7953\n","Epoch 39/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8338 - accuracy: 0.7761\n","Epoch 40/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.9241 - accuracy: 0.7521\n","Epoch 41/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 1.0433 - accuracy: 0.7279\n","Epoch 42/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 1.0706 - accuracy: 0.7217\n","Epoch 43/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 1.0197 - accuracy: 0.7326\n","Epoch 44/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.9034 - accuracy: 0.7608\n","Epoch 45/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8309 - accuracy: 0.7820\n","Epoch 46/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7982 - accuracy: 0.7897\n","Epoch 47/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7841 - accuracy: 0.7908\n","Epoch 48/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7927 - accuracy: 0.7896\n","Epoch 49/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8170 - accuracy: 0.7819\n","Epoch 50/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8384 - accuracy: 0.7782\n","Epoch 51/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.9316 - accuracy: 0.7555\n","Epoch 52/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 1.0866 - accuracy: 0.7223\n","Epoch 53/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 1.0799 - accuracy: 0.7219\n","Epoch 54/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.9553 - accuracy: 0.7465\n","Epoch 55/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8576 - accuracy: 0.7730\n","Epoch 56/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8076 - accuracy: 0.7838\n","Epoch 57/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7460 - accuracy: 0.8003\n","Epoch 58/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7233 - accuracy: 0.8047\n","Epoch 59/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7196 - accuracy: 0.8094\n","Epoch 60/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7278 - accuracy: 0.8035\n","Epoch 61/100\n","12038/12038 [==============================] - 27s 2ms/sample - loss: 0.7964 - accuracy: 0.7863\n","Epoch 62/100\n","12038/12038 [==============================] - 27s 2ms/sample - loss: 0.9531 - accuracy: 0.7464\n","Epoch 63/100\n","12038/12038 [==============================] - 27s 2ms/sample - loss: 1.0774 - accuracy: 0.7192\n","Epoch 64/100\n","12038/12038 [==============================] - 27s 2ms/sample - loss: 1.0504 - accuracy: 0.7259\n","Epoch 65/100\n","12038/12038 [==============================] - 35s 3ms/sample - loss: 0.9104 - accuracy: 0.7574\n","Epoch 66/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8453 - accuracy: 0.7737\n","Epoch 67/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7791 - accuracy: 0.7897\n","Epoch 68/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7714 - accuracy: 0.7965\n","Epoch 69/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7990 - accuracy: 0.7879\n","Epoch 70/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7902 - accuracy: 0.7881\n","Epoch 71/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8119 - accuracy: 0.7863\n","Epoch 72/100\n","12038/12038 [==============================] - 29s 2ms/sample - loss: 0.8397 - accuracy: 0.7786\n","Epoch 73/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8870 - accuracy: 0.7611\n","Epoch 74/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.9289 - accuracy: 0.7537\n","Epoch 75/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.9489 - accuracy: 0.7485\n","Epoch 76/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.9056 - accuracy: 0.7576\n","Epoch 77/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8397 - accuracy: 0.7746\n","Epoch 78/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7986 - accuracy: 0.7848\n","Epoch 79/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7754 - accuracy: 0.7924\n","Epoch 80/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7541 - accuracy: 0.7980\n","Epoch 81/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7441 - accuracy: 0.8026\n","Epoch 82/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7338 - accuracy: 0.8050\n","Epoch 83/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7575 - accuracy: 0.8001\n","Epoch 84/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8170 - accuracy: 0.7807\n","Epoch 85/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8681 - accuracy: 0.7708\n","Epoch 86/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.9700 - accuracy: 0.7461\n","Epoch 87/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 1.0499 - accuracy: 0.7279\n","Epoch 88/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.9914 - accuracy: 0.7377\n","Epoch 89/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8858 - accuracy: 0.7632\n","Epoch 90/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8125 - accuracy: 0.7801\n","Epoch 91/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8262 - accuracy: 0.7785\n","Epoch 92/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7602 - accuracy: 0.7976\n","Epoch 93/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7211 - accuracy: 0.8084\n","Epoch 94/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7329 - accuracy: 0.8036\n","Epoch 95/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.7736 - accuracy: 0.7951\n","Epoch 96/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8070 - accuracy: 0.7854\n","Epoch 97/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.8132 - accuracy: 0.7835\n","Epoch 98/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.9056 - accuracy: 0.7661\n","Epoch 99/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 1.0367 - accuracy: 0.7358\n","Epoch 100/100\n","12038/12038 [==============================] - 28s 2ms/sample - loss: 0.9993 - accuracy: 0.7423\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1v2puiq3SlBf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":198},"outputId":"fe7d0854-ac4e-4ff5-af42-9c834bd62dd7","executionInfo":{"status":"error","timestamp":1579231010527,"user_tz":480,"elapsed":518,"user":{"displayName":"Hieu Quoc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBXboZp2dMx_so4JiaOdf8YR1jpP73S07Pde39vvw=s64","userId":"07041430737003441740"}}},"source":["import matplotlib.pyplot as plt\n","\n","\n","def plot_graphs(history, string):\n","  plt.plot(history.history[string])\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(string)\n","  plt.show()\n","\n","plot_graphs(history, 'accuracy')"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-6cfb583023e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplot_graphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"]}]},{"cell_type":"code","metadata":{"id":"dOUYhNmFTvfS","colab_type":"code","colab":{}},"source":["# Note that there are no line breaks in the prediction, so you'll have to \n","# add them manually to turn the word stream into poetry.\n","seed_text = \"Help me Obi-Wan Kenobi, you are my only hope\"\n","next_words = 100\n","  \n","for _ in range(next_words):\n","\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n","\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","\tpredicted = model.predict_classes(token_list, verbose=0)\n","\toutput_word = \"\"\n","\tfor word, index in tokenizer.word_index.items():\n","\t\tif index == predicted:\n","\t\t\toutput_word = word\n","\t\t\tbreak\n","\tseed_text += \" \" + output_word\n","print(seed_text)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qOJsrPMrWjmi","colab_type":"text"},"source":["### NOTE:\n","- This approach works very well until you have **very large bodies of text with many many words**. So for example, you could try the complete works of Shakespeare and you'll likely **hit memory errors**, as assigning the one-hot encodings of the labels to matrices that have over 31,477 elements, which is the number of unique words in the collection, and there are over 15 million sequences generated using the algorithm that we showed here. \n","\n","- So the labels alone would require the storage of many terabytes of RAM. So for your next task, you'll go through a workbook by yourself that uses **character-based prediction**. The full number of unique characters in a corpus is far less than the full number of unique words, at least in English. https://www.tensorflow.org/tutorials/text/text_generation\n","\n","  So the same principles that you use to predict words can be used to apply here."]},{"cell_type":"code","metadata":{"id":"DOgtS2QrXB3h","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}